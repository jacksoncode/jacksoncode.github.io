#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HTMLé“¾æ¥è¿é€šæ€§æ£€æµ‹å·¥å…·
ç”¨äºæ£€æµ‹HTMLæ–‡ä»¶ä¸­çš„HTTPSé“¾æ¥æ˜¯å¦å¯ä»¥æ­£å¸¸è®¿é—®

ä½œè€…: Jackson
æ—¥æœŸ: 2025-08-27
"""

import urllib.request
import urllib.error
import re
import time
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urljoin, urlparse
import argparse
from pathlib import Path
import ssl

class LinkChecker:
    def __init__(self, timeout=10, max_workers=10):
        """
        åˆå§‹åŒ–é“¾æ¥æ£€æŸ¥å™¨
        :param timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        :param max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
        """
        self.timeout = timeout
        self.max_workers = max_workers
        
        # åˆ›å»ºSSLä¸Šä¸‹æ–‡ï¼Œå…è®¸æœªéªŒè¯çš„è¯ä¹¦ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        self.ssl_context = ssl.create_default_context()
        self.ssl_context.check_hostname = False
        self.ssl_context.verify_mode = ssl.CERT_NONE
        
    def extract_links_from_html(self, html_file):
        """
        ä»HTMLæ–‡ä»¶ä¸­æå–æ‰€æœ‰çš„HTTPSé“¾æ¥
        :param html_file: HTMLæ–‡ä»¶è·¯å¾„
        :return: HTTPSé“¾æ¥åˆ—è¡¨
        """
        try:
            with open(html_file, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return []
            
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–hrefå’Œsrcä¸­çš„HTTPSé“¾æ¥
        https_pattern = r'(?:href|src)=["\']?(https://[^"\'\s>]+)["\']?'
        matches = re.findall(https_pattern, content, re.IGNORECASE)
        
        # å»é‡å¹¶è¿”å›
        unique_links = list(set(matches))
        return unique_links
        
    def check_single_link(self, url):
        """
        æ£€æŸ¥å•ä¸ªé“¾æ¥çš„è¿é€šæ€§
        :param url: è¦æ£€æŸ¥çš„URL
        :return: (url, status, response_time, error_msg)
        """
        start_time = time.time()
        try:
            # åˆ›å»ºè¯·æ±‚å¯¹è±¡
            req = urllib.request.Request(
                url,
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
            )
            
            # å‘é€è¯·æ±‚
            with urllib.request.urlopen(req, timeout=self.timeout, context=self.ssl_context) as response:
                response_time = time.time() - start_time
                if response.getcode() == 200:
                    return (url, 'OK', response_time, None)
                else:
                    return (url, 'ERROR', response_time, f'HTTP {response.getcode()}')
                    
        except urllib.error.HTTPError as e:
            response_time = time.time() - start_time
            return (url, 'ERROR', response_time, f'HTTP {e.code}: {e.reason}')
        except urllib.error.URLError as e:
            response_time = time.time() - start_time
            if 'timeout' in str(e.reason).lower():
                return (url, 'TIMEOUT', response_time, 'è¯·æ±‚è¶…æ—¶')
            else:
                return (url, 'CONNECTION_ERROR', response_time, f'è¿æ¥é”™è¯¯: {e.reason}')
        except Exception as e:
            response_time = time.time() - start_time
            return (url, 'ERROR', response_time, f'æœªçŸ¥é”™è¯¯: {str(e)}')
    
    def check_links(self, links):
        """
        å¹¶å‘æ£€æŸ¥å¤šä¸ªé“¾æ¥
        :param links: é“¾æ¥åˆ—è¡¨
        :return: æ£€æŸ¥ç»“æœåˆ—è¡¨
        """
        results = []
        
        print(f"ğŸ” å¼€å§‹æ£€æŸ¥ {len(links)} ä¸ªHTTPSé“¾æ¥...")
        print("=" * 80)
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_url = {executor.submit(self.check_single_link, url): url for url in links}
            
            # æ”¶é›†ç»“æœ
            for i, future in enumerate(as_completed(future_to_url), 1):
                url, status, response_time, error_msg = future.result()
                results.append((url, status, response_time, error_msg))
                
                # å®æ—¶æ˜¾ç¤ºè¿›åº¦
                status_icon = {
                    'OK': 'âœ…',
                    'ERROR': 'âŒ', 
                    'TIMEOUT': 'â°',
                    'CONNECTION_ERROR': 'ğŸ”Œ'
                }.get(status, 'â“')
                
                print(f"[{i:3d}/{len(links)}] {status_icon} {status:15} {response_time:6.2f}s - {url}")
                if error_msg:
                    print(f"      â†³ {error_msg}")
                    
        return results
    
    def generate_report(self, results):
        """
        ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š
        :param results: æ£€æŸ¥ç»“æœåˆ—è¡¨
        """
        print("\n" + "=" * 80)
        print("ğŸ“Š æ£€æŸ¥æŠ¥å‘Š")
        print("=" * 80)
        
        total = len(results)
        ok_count = sum(1 for _, status, _, _ in results if status == 'OK')
        error_count = sum(1 for _, status, _, _ in results if status == 'ERROR')
        timeout_count = sum(1 for _, status, _, _ in results if status == 'TIMEOUT')
        connection_error_count = sum(1 for _, status, _, _ in results if status == 'CONNECTION_ERROR')
        
        print(f"âœ… æ­£å¸¸è®¿é—®: {ok_count:3d} ({ok_count/total*100:5.1f}%)")
        print(f"âŒ è®¿é—®é”™è¯¯: {error_count:3d} ({error_count/total*100:5.1f}%)")  
        print(f"â° è¯·æ±‚è¶…æ—¶: {timeout_count:3d} ({timeout_count/total*100:5.1f}%)")
        print(f"ğŸ”Œ è¿æ¥é”™è¯¯: {connection_error_count:3d} ({connection_error_count/total*100:5.1f}%)")
        print(f"ğŸ“ˆ æ€»è®¡é“¾æ¥: {total:3d}")
        
        # æ˜¾ç¤ºé—®é¢˜é“¾æ¥
        problem_results = [(url, status, error_msg) for url, status, _, error_msg in results if status != 'OK']
        
        if problem_results:
            print(f"\nâš ï¸  å‘ç° {len(problem_results)} ä¸ªé—®é¢˜é“¾æ¥:")
            print("-" * 80)
            for url, status, error_msg in problem_results:
                status_icon = {'ERROR': 'âŒ', 'TIMEOUT': 'â°', 'CONNECTION_ERROR': 'ğŸ”Œ'}.get(status, 'â“')
                print(f"{status_icon} {url}")
                if error_msg:
                    print(f"   â†³ {error_msg}")
        else:
            print(f"\nğŸ‰ æ‰€æœ‰é“¾æ¥éƒ½å¯ä»¥æ­£å¸¸è®¿é—®ï¼")


def main():
    parser = argparse.ArgumentParser(description='HTMLé“¾æ¥è¿é€šæ€§æ£€æµ‹å·¥å…·')
    parser.add_argument('html_file', nargs='?', default='nav.html', 
                       help='è¦æ£€æŸ¥çš„HTMLæ–‡ä»¶è·¯å¾„ (é»˜è®¤: nav.html)')
    parser.add_argument('--timeout', '-t', type=int, default=10,
                       help='è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) (é»˜è®¤: 10)')
    parser.add_argument('--workers', '-w', type=int, default=10,
                       help='æœ€å¤§å¹¶å‘çº¿ç¨‹æ•° (é»˜è®¤: 10)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥HTMLæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    html_path = Path(args.html_file)
    if not html_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.html_file}")
        sys.exit(1)
    
    print(f"ğŸŒ HTMLé“¾æ¥è¿é€šæ€§æ£€æµ‹å·¥å…·")
    print(f"ğŸ“„ æ–‡ä»¶: {args.html_file}")
    print(f"â±ï¸  è¶…æ—¶: {args.timeout}ç§’")
    print(f"ğŸ”„ å¹¶å‘: {args.workers}çº¿ç¨‹")
    print()
    
    # åˆ›å»ºé“¾æ¥æ£€æŸ¥å™¨
    checker = LinkChecker(timeout=args.timeout, max_workers=args.workers)
    
    # æå–é“¾æ¥
    links = checker.extract_links_from_html(args.html_file)
    
    if not links:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•HTTPSé“¾æ¥")
        sys.exit(0)
        
    # æ£€æŸ¥é“¾æ¥
    results = checker.check_links(links)
    
    # ç”ŸæˆæŠ¥å‘Š
    checker.generate_report(results)


if __name__ == '__main__':
    main()