# 文本处理三剑客

## 1 grep - 文本搜索工具

### 1.1 grep基础用法

#### 1.1.1 基本搜索

```bash
#!/bin/bash
# grep基础用法示例

# 搜索单个文件
grep "root" /etc/passwd

# 搜索多个文件
grep "error" /var/log/syslog /var/log/auth.log

# 递归搜索目录
grep -r "error" /var/log/

# 忽略大小写
grep -i "ERROR" /var/log/syslog

# 显示行号
grep -n "root" /etc/passwd

# 显示不匹配的行
grep -v "nologin" /etc/passwd

# 统计匹配行数
grep -c "root" /etc/passwd
```

#### 1.1.2 高级搜索选项

```bash
#!/bin/bash
# grep高级选项示例

# 整词匹配
grep -w "root" /etc/passwd

# 显示上下文
grep -C 2 "error" /var/log/syslog

# 只显示匹配部分
grep -o "[0-9]\+" /var/log/syslog

# 使用扩展正则
grep -E "root|admin" /etc/passwd

# 固定字符串匹配
grep -F "[error]" /var/log/syslog

# 排除文件
grep -r "error" /var/log/ --exclude="*.gz"
```

### 1.2 grep实战应用

#### 1.2.1 日志分析

```bash
#!/bin/bash
# grep日志分析示例

# 分析Apache访问日志
LOG_FILE="/var/log/apache2/access.log"

# 查找404错误
echo "404错误请求:"
grep " 404 " "$LOG_FILE" | head -10

# 查找特定IP的访问
echo "IP 192.168.1.100 的访问:"
grep "^192.168.1.100" "$LOG_FILE" | head -5

# 查找特定时间段的日志
echo "今天的访问日志:"
grep "$(date +%d/%b/%Y)" "$LOG_FILE" | wc -l

# 查找慢查询（响应时间>5秒）
echo "慢查询 (>5秒):"
grep -E "[0-9]+ [0-9]{5,}" "$LOG_FILE" | head -5

# 查找爬虫访问
echo "搜索引擎爬虫:"
grep -i "googlebot\|bingbot\|slurp" "$LOG_FILE" | head -5
```

#### 1.2.2 系统监控

```bash
#!/bin/bash
# grep系统监控示例

# 检查系统服务
check_service() {
    local service="$1"
    if systemctl status "$service" 2>/dev/null | grep -q "active (running)"; then
        echo "✅ $service 运行正常"
    else
        echo "❌ $service 未运行"
    fi
}

# 检查磁盘空间
check_disk_space() {
    local threshold="${1:-80}"
    df -h | grep -E "^/dev/" | while read filesystem size used avail use mount; do
        use_num=${use%?}
        if [ "$use_num" -gt "$threshold" ]; then
            echo "⚠️  $mount 使用率: $use (超过${threshold}%)"
        else
            echo "✅ $mount 使用率: $use"
        fi
    done
}

# 检查网络连接
check_network() {
    local hosts=("google.com" "github.com")
    for host in "${hosts[@]}"; do
        if ping -c 1 "$host" >/dev/null 2>&1; then
            echo "✅ $host 可访问"
        else
            echo "❌ $host 不可访问"
        fi
    done
}

# 使用监控函数
echo "=== 系统状态检查 ==="
check_service "sshd"
check_service "nginx"
check_service "mysql"
echo
echo "=== 磁盘空间检查 ==="
check_disk_space 85
echo
echo "=== 网络连接检查 ==="
check_network
```

## 2 sed - 流编辑器

### 2.1 sed基础用法

#### 2.1.1 基本替换

```bash
#!/bin/bash
# sed基础用法示例

# 简单替换
echo "hello world" | sed 's/world/linux/'

# 全局替换
echo "hello world world" | sed 's/world/linux/g'

# 指定行替换
echo -e "line1\nline2\nline3" | sed '2s/line/LINE/'

# 删除行
echo -e "line1\nline2\nline3" | sed '2d'

# 插入行
echo -e "line1\nline3" | sed '2i\line2'

# 追加行
echo -e "line1\nline2" | sed '2a\line3'
```

#### 2.1.2 高级sed技巧

```bash
#!/bin/bash
# sed高级技巧示例

# 多命令组合
echo -e "line1\nline2\nline3" | sed -e '1s/line/LINE/' -e '3s/line/LINE/'

# 使用地址范围
echo -e "start\nline1\nline2\nend" | sed '/start/,/end/s/line/LINE/'

# 反向引用
echo "hello world" | sed 's/\(hello\) \(world\)/\2 \1/'

# 使用变量
name="world"
echo "hello $name" | sed "s/$name/linux/"

# 就地编辑（谨慎使用）
# sed -i 's/old/new/g' filename

# 备份编辑
# sed -i.bak 's/old/new/g' filename
```

### 2.2 sed实战应用

#### 2.2.1 配置文件管理

```bash
#!/bin/bash
# sed配置文件管理示例

# 更新配置文件
update_config() {
    local config_file="$1"
    local key="$2"
    local value="$3"
    
    if grep -q "^$key" "$config_file"; then
        sed -i "s/^$key.*/$key=$value/" "$config_file"
    else
        echo "$key=$value" >> "$config_file"
    fi
}

# 注释配置项
comment_config() {
    local config_file="$1"
    local key="$2"
    
    sed -i "s/^$key/#$key/" "$config_file"
}

# 取消注释
uncomment_config() {
    local config_file="$1"
    local key="$2"
    
    sed -i "s/^#$key/$key/" "$config_file"
}

# 提取配置值
get_config_value() {
    local config_file="$1"
    local key="$2"
    
    sed -n "s/^$key=\(.*\)/\1/p" "$config_file"
}

# 使用配置管理
CONFIG_FILE="/tmp/test.conf"
cat > "$CONFIG_FILE" << EOF
# 测试配置文件
server_name=localhost
port=80
max_connections=100
EOF

echo "原始配置:"
cat "$CONFIG_FILE"

echo "更新端口..."
update_config "$CONFIG_FILE" "port" "8080"

echo "注释max_connections..."
comment_config "$CONFIG_FILE" "max_connections"

echo "取消注释..."
uncomment_config "$CONFIG_FILE" "max_connections"

echo "最终配置:"
cat "$CONFIG_FILE"
```

#### 2.2.2 文本处理

```bash
#!/bin/bash
# sed文本处理示例

# 格式化文本
format_text() {
    local input_file="$1"
    
    sed '
        # 移除行尾空格
        s/[[:space:]]*$//
        
        # 将空行替换为分隔符
        /^$/s//---/
        
        # 大写标题行
        /^# /s/.*/\U&/
        
        # 缩进代码块
        /^    /s/^/  /
        
        # 添加行号
        =
        
        # 合并行号和内容
        N
        s/\n/ /g
    ' "$input_file"
}

# 提取URL
extract_urls() {
    local input_file="$1"
    
    sed -n '
        # 查找http/https URL
        /https\?:\/\//{
            # 提取URL
            s/.*\(https\?:\/\/[^[:space:]"<>]*\).*/\1/p
        }
    ' "$input_file"
}

# 清理日志
cleanup_log() {
    local log_file="$1"
    
    sed -i '
        # 移除时间戳
        s/^[0-9-]* [0-9:]* //
        
        # 匿名化IP
        s/[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}/[IP]/g
        
        # 标准化错误级别
        s/ERROR:/[ERROR]/g
        s/WARNING:/[WARN]/g
        s/INFO:/[INFO]/g
    ' "$log_file"
}

# 使用文本处理
cat > /tmp/sample.txt << EOF
# 这是一个标题

    这是一段代码
    包含多个空格

这是一个URL: https://example.com
EOF

echo "格式化文本:"
format_text /tmp/sample.txt

echo "提取URL:"
extract_urls /tmp/sample.txt
```

## 3 awk - 文本处理语言

### 3.1 awk基础用法

#### 3.1.1 基本语法

```bash
#!/bin/bash
# awk基础用法示例

# 打印整行
awk '{print}' /etc/passwd

# 打印特定字段
awk -F: '{print $1}' /etc/passwd

# 打印多个字段
awk -F: '{print $1, $3}' /etc/passwd

# 添加自定义输出
awk -F: '{print "User:", $1, "UID:", $3}' /etc/passwd

# 使用条件
awk -F: '$3 > 1000 {print $1, $3}' /etc/passwd

# 使用BEGIN和END
awk -F: 'BEGIN{print "用户名 UID"} {print $1, $3} END{print "总计:", NR}' /etc/passwd
```

#### 3.1.2 高级awk特性

```bash
#!/bin/bash
# awk高级特性示例

# 使用数组
awk -F: '{
    shell[$7]++
} 
END {
    for (s in shell) 
        printf "%-20s %d\n", s, shell[s]
}' /etc/passwd

# 使用数学运算
awk -F: '$3 > 100 {
    sum += $3
    count++
} 
END {
    if (count > 0)
        printf "平均UID: %.2f\n", sum/count
}' /etc/passwd

# 字符串处理
awk -F: '{
    printf "%-10s %s\n", $1, toupper($1)
}' /etc/passwd

# 格式化输出
awk -F: 'BEGIN{
    printf "%-15s %-5s %-10s\n", "用户名", "UID", "主目录"
    printf "%-15s %-5s %-10s\n", "------", "---", "--------"
}
{
    printf "%-15s %-5d %-10s\n", $1, $3, $6
}' /etc/passwd
```

### 3.2 awk实战应用

#### 3.2.1 系统监控

```bash
#!/bin/bash
# awk系统监控示例

# 进程监控
monitor_processes() {
    echo "=== 进程监控 ==="
    ps aux |
    awk 'NR>1 {
        if ($3 > 10.0) 
            printf "%-20s %8.1f%%\n", $11, $3
    }' |
    sort -k2 -nr |
    head -10
}

# 磁盘监控
monitor_disk() {
    echo "=== 磁盘监控 ==="
    df -h |
    awk 'NR>1 {
        use = $5
        gsub(/%/, "", use)
        if (use > 80) 
            printf "%-20s %6s 警告\n", $1, $5
        else
            printf "%-20s %6s 正常\n", $1, $5
    }'
}

# 内存监控
monitor_memory() {
    echo "=== 内存监控 ==="
    free -m |
    awk 'NR==2{
        total = $2
        used = $3
        free = $4
        percentage = (used / total) * 100
        printf "总内存: %dMB, 已用: %dMB (%.1f%%), 可用: %dMB\n", 
               total, used, percentage, free
    }'
}

# 网络监控
monitor_network() {
    echo "=== 网络监控 ==="
    ss -tuln |
    awk 'NR>1 {
        split($4, addr, ":")
        printf "%-8s %-22s %-10s\n", $1, $4, $6
    }' |
    sort -k2
}

# 使用监控函数
monitor_processes
echo
monitor_disk
echo
monitor_memory
echo
monitor_network
```

#### 3.2.2 日志分析

```bash
#!/bin/bash
# awk日志分析示例

# Apache日志分析
analyze_apache() {
    local log_file="/var/log/apache2/access.log"
    
    if [ ! -f "$log_file" ]; then
        echo "Apache日志文件不存在: $log_file"
        return 1
    fi
    
    echo "=== Apache日志分析 ==="
    echo "文件: $log_file"
    echo ""
    
    # 基本统计
    echo "总请求数: $(wc -l < "$log_file")"
    echo "独立IP数: $(awk '{print $1}' "$log_file" | sort | uniq | wc -l)"
    echo ""
    
    # IP访问统计
    echo "访问最多的IP:"
    awk '{print $1}' "$log_file" |
    sort | uniq -c | sort -nr |
    awk 'NR<=10 {printf "%-15s %6d 次\n", $2, $1}'
    echo ""
    
    # 状态码统计
    echo "状态码统计:"
    awk '{print $9}' "$log_file" |
    sort | uniq -c | sort -nr |
    awk '{printf "状态码 %3s: %6d 次\n", $2, $1}'
    echo ""
    
    # 请求路径统计
    echo "访问最多的路径:"
    awk '{print $7}' "$log_file" |
    sort | uniq -c | sort -nr |
    awk 'NR<=10 {printf "%-40s %6d 次\n", $2, $1}'
    echo ""
    
    # 用户代理统计
    echo "常见用户代理:"
    awk -F'"' '{print $6}' "$log_file" |
    sort | uniq -c | sort -nr |
    awk 'NR<=5 {printf "%-50s %6d 次\n", substr($2,1,50), $1}'
}

# Nginx日志分析
analyze_nginx() {
    local log_file="/var/log/nginx/access.log"
    
    if [ ! -f "$log_file" ]; then
        echo "Nginx日志文件不存在: $log_file"
        return 1
    fi
    
    echo "=== Nginx日志分析 ==="
    echo "文件: $log_file"
    echo ""
    
    # 响应时间分析
    echo "响应时间统计:"
    awk '$NF ~ /^[0-9]+$/ {
        times[NR] = $NF
        sum += $NF
        if ($NF > max) max = $NF
        if ($NF < min || min == 0) min = $NF
    } END {
        if (NR > 0) {
            avg = sum / NR
            printf "平均: %.2fms, 最大: %dms, 最小: %dms\n", avg, max, min
        }
    }' "$log_file"
    echo ""
    
    # 错误请求
    echo "错误请求:"
    awk '$9 >= 400 {print $1, $7, $9}' "$log_file" |
    sort | uniq -c | sort -nr |
    awk 'NR<=10 {printf "%-15s %-30s %3s 次\n", $2, $3, $1}'
}

# 系统日志分析
analyze_syslog() {
    local log_file="/var/log/syslog"
    
    if [ ! -f "$log_file" ]; then
        echo "系统日志文件不存在: $log_file"
        return 1
    fi
    
    echo "=== 系统日志分析 ==="
    echo "文件: $log_file"
    echo ""
    
    # 错误统计
    echo "错误级别统计:"
    awk '{print $5}' "$log_file" |
    sort | uniq -c | sort -nr |
    awk 'NR<=10 {printf "%-20s %6d 次\n", $2, $1}'
    echo ""
    
    # 时间分布
    echo "时间分布:"
    awk '{print $1, $2}' "$log_file" |
    cut -d: -f1,2 |
    sort | uniq -c | sort -nr |
    awk 'NR<=10 {printf "%-5s %6d 次\n", $2, $1}'
}

# 使用分析函数
echo "=== 日志分析系统 ==="
analyze_apache 2>/dev/null
analyze_nginx 2>/dev/null
analyze_syslog 2>/dev/null
```

## 4 三剑客组合使用

### 4.1 管道组合

```bash
#!/bin/bash
# 三剑客组合使用示例

# 综合日志分析
comprehensive_log_analysis() {
    local log_file="/var/log/apache2/access.log"
    
    echo "=== 综合日志分析 ==="
    echo "文件: $log_file"
    echo ""
    
    # 使用grep过滤，awk分析，sed格式化
    grep -v "^#" "$log_file" |
    awk '{
        ip[$1]++
        status[$9]++
        bytes[$1] += $10
    } 
    END {
        print "=== IP统计 ==="
        for (i in ip) 
            printf "%-15s %6d 次 %10d 字节\n", i, ip[i], bytes[i]
        
        print ""
        print "=== 状态码统计 ==="
        for (s in status) 
            printf "状态码 %3s: %6d 次\n", s, status[s]
    }' |
    sed 's/^/  /'
}

# 系统监控报告
system_monitoring_report() {
    echo "=== 系统监控报告 ==="
    echo "生成时间: $(date)"
    echo ""
    
    # CPU监控
    echo "=== CPU使用 ==="
    ps aux |
    grep -v "^USER" |
    awk '$3 > 5.0 {
        printf "%-20s %8.1f%%\n", $11, $3
    }' |
    sort -k2 -nr |
    head -10 |
    sed 's/^/  /'
    
    echo ""
    
    # 内存监控
    echo "=== 内存使用 ==="
    free -m |
    sed -n '2p' |
    awk '{
        total = $2
        used = $3
        free = $4
        printf "总内存: %dMB, 已用: %dMB (%.1f%%), 可用: %dMB\n", 
               total, used, (used/total)*100, free
    }' |
    sed 's/^/  /'
    
    echo ""
    
    # 磁盘监控
    echo "=== 磁盘使用 ==="
    df -h |
    grep -E "^/dev/" |
    awk '$5+0 > 80 {
        printf "%-20s %6s 警告\n", $1, $5
    }' |
    sed 's/^/  /'
}

# 网络监控
network_monitoring() {
    echo "=== 网络连接监控 ==="
    
    # 监听端口
    echo "监听端口:"
    ss -tuln |
    grep LISTEN |
    awk '{
        split($4, addr, ":")
        port = addr[length(addr)]
        printf "%-8s %-6s %-10s\n", $1, port, $6
    }' |
    sort -k2 -n |
    sed 's/^/  /'
    
    echo ""
    
    # 连接统计
    echo "连接统计:"
    ss -t |
    grep -v "State" |
    awk '{
        state[$1]++
    } 
    END {
        for (s in state) 
            printf "%-10s %6d\n", s, state[s]
    }' |
    sed 's/^/  /'
}

# 使用组合分析
echo "=== 系统综合分析 ==="
comprehensive_log_analysis 2>/dev/null
system_monitoring_report
network_monitoring
```

### 4.2 性能优化

```bash
#!/bin/bash
# 性能优化示例

# 优化大文件处理
optimize_large_file_processing() {
    local large_file="/var/log/bigfile.log"
    
    echo "=== 性能优化示例 ==="
    echo "文件: $large_file"
    echo ""
    
    # 方法1: 直接处理（慢）
    echo "方法1: 直接处理"
    time awk '{print $1}' "$large_file" >/dev/null 2>&1
    
    # 方法2: 使用grep预处理（快）
    echo "方法2: 使用grep预处理"
    time grep -v "^#" "$large_file" | awk '{print $1}' >/dev/null 2>&1
    
    # 方法3: 使用sed清理（更快）
    echo "方法3: 使用sed清理"
    time sed '/^#/d' "$large_file" | awk '{print $1}' >/dev/null 2>&1
    
    # 方法4: 并行处理（最快）
    echo "方法4: 并行处理"
    time awk '{print $1}' "$large_file" | sort -u >/dev/null 2>&1
}

# 内存优化
memory_optimization() {
    echo "=== 内存优化 ==="
    
    # 使用awk处理大文件
    awk '{
        # 只存储必要信息
        if ($3 > 100) {
            key = $1
            sum[key] += $2
            count[key]++
        }
    } 
    END {
        # 只输出结果
        for (k in sum) {
            printf "%-10s %8.2f\n", k, sum[k]/count[k]
        }
    }' /var/log/syslog
}

# 使用优化
# optimize_large_file_processing 2>/dev/null
# memory_optimization
```

## 5 实用脚本集合

### 5.1 日志分析脚本

```bash
#!/bin/bash
# 完整日志分析脚本

LOG_ANALYZER() {
    local log_file="$1"
    local output_file="${2:-/tmp/analysis_$(basename "$log_file")_$(date +%Y%m%d_%H%M%S).txt}"
    
    if [ ! -f "$log_file" ]; then
        echo "错误: 文件 $log_file 不存在"
        return 1
    fi
    
    {
        echo "=== 日志分析报告 ==="
        echo "文件: $log_file"
        echo "大小: $(du -h "$log_file" | cut -f1)"
        echo "行数: $(wc -l < "$log_file")"
        echo "生成时间: $(date)"
        echo ""
        
        # 使用三剑客进行分析
        echo "=== 错误统计 ==="
        grep -i "error\|fail\|critical" "$log_file" |
        awk '{
            error_type = toupper($5)
            errors[error_type]++
        } 
        END {
            for (type in errors)
                printf "%-15s %6d\n", type, errors[type]
        }' |
        sort -k2 -nr
        
        echo ""
        
        echo "=== IP地址统计 ==="
        grep -oE '[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}' "$log_file" |
        sort | uniq -c | sort -nr |
        head -10 |
        awk '{printf "%-15s %6d\n", $2, $1}'
        
        echo ""
        
        echo "=== 时间分布 ==="
        sed 's/^[0-9-]* [0-9:]* //' "$log_file" |
        cut -d: -f1,2 |
        sort | uniq -c |
        awk '{printf "%-5s %6d\n", $2, $1}'
        
        echo ""
        
        echo "=== 关键词云 ==="
        grep -oE '\b[a-zA-Z]{4,}\b' "$log_file" |
        tr 'A-Z' 'a-z' |
        sort | uniq -c | sort -nr |
        head -20 |
        awk '{printf "%-15s %6d\n", $2, $1}'
        
    } > "$output_file"
    
    echo "分析报告已生成: $output_file"
}

# 使用日志分析器
# LOG_ANALYZER /var/log/syslog
```

### 5.2 系统管理脚本

```bash
#!/bin/bash
# 系统管理脚本

SYSTEM_MANAGER() {
    local action="$1"
    
    case "$action" in
        "process")
            echo "=== 进程管理 ==="
            ps aux |
            awk 'NR>1 && $3 > 5.0 {
                printf "%-20s %8.1f%% %8s\n", $11, $3, $2
            }' |
            sort -k2 -nr |
            head -10
            ;;
        
        "disk")
            echo "=== 磁盘管理 ==="
            df -h |
            awk 'NR>1 {
                use = $5
                gsub(/%/, "", use)
                status = (use > 90) ? "危险" : (use > 80) ? "警告" : "正常"
                printf "%-20s %6s %s\n", $1, $5, status
            }'
            ;;
        
        "memory")
            echo "=== 内存管理 ==="
            free -m |
            awk 'NR==2{
                total = $2
                used = $3
                free = $4
                cached = $6
                buffers = $5
                
                printf "总内存: %dMB\n", total
                printf "已使用: %dMB (%.1f%%)\n", used, (used/total)*100
                printf "可用: %dMB\n", free + cached + buffers
                printf "缓存: %dMB\n", cached + buffers
            }'
            ;;
        
        "network")
            echo "=== 网络管理 ==="
            ss -tuln |
            awk 'NR>1 {
                split($4, addr, ":")
                port = addr[length(addr)]
                printf "%-8s %-6s %-10s\n", $1, port, $6
            }' |
            sort -k2 -n
            ;;
        
        *)
            echo "使用方法: $0 {process|disk|memory|network}"
            ;;
    esac
}

# 使用系统管理器
# SYSTEM_MANAGER process
# SYSTEM_MANAGER disk
# SYSTEM_MANAGER memory
# SYSTEM_MANAGER network
```

这些示例展示了如何有效地结合使用grep、sed和awk这三个强大的文本处理工具，从简单的文本搜索到复杂的系统监控和日志分析，都能发挥重要作用。