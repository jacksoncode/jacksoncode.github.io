# 正则表达式

## 1 正则表达式基础

### 1.1 基本语法

正则表达式（Regular Expression）是一种用于匹配字符串模式的强大工具。Linux系统中主要有两种正则表达式风格：

- **基本正则表达式（BRE）**：grep、sed等默认使用
- **扩展正则表达式（ERE）**：egrep、grep -E、awk等使用

```bash
#!/bin/bash
# 正则表达式基础示例

# 基本匹配
echo "hello world" | grep "hello"
echo "hello world" | grep -E "hello|world"

# 字符匹配
echo "cat" | grep "c.t"      # 匹配任意字符
echo "caat" | grep "ca\{2\}t"  # 基本正则
echo "caat" | grep -E "ca{2}t"  # 扩展正则

# 行首行尾匹配
echo "hello" | grep "^hello"
echo "world" | grep "world$"
echo "hello world" | grep "^hello.*world$"
```

### 1.2 字符类与元字符

#### 1.2.1 字符类

```bash
#!/bin/bash
# 字符类示例

# 单个字符匹配
echo "abc" | grep "[abc]"      # 匹配a、b或c
echo "abc" | grep "[^abc]"     # 匹配非a、b、c的字符
echo "abc123" | grep "[a-z]"   # 匹配小写字母
echo "ABC123" | grep "[A-Z]"   # 匹配大写字母
echo "abc123" | grep "[0-9]"   # 匹配数字
echo "abc123" | grep "[a-zA-Z0-9]"  # 匹配字母数字

# 预定义字符类
echo "hello123" | grep -E "\w"    # 匹配单词字符
echo "hello 123" | grep -E "\W"   # 匹配非单词字符
echo "hello123" | grep -E "\d"    # 匹配数字
echo "hello" | grep -E "\D"       # 匹配非数字
echo "hello world" | grep -E "\s"  # 匹配空白字符
echo "hello" | grep -E "\S"        # 匹配非空白字符
```

#### 1.2.2 量词

```bash
#!/bin/bash
# 量词示例

# 基本量词
echo "a" | grep "a\?"        # 0或1次
echo "aa" | grep "a\+"       # 1次或多次
echo "" | grep "a*"          # 0次或多次
echo "aaa" | grep "a\{3\}"   # 恰好3次
echo "aa" | grep "a\{1,3\}"  # 1到3次
echo "aaaa" | grep "a\{2,\}"  # 至少2次

# 扩展正则量词
echo "a" | grep -E "a?"
echo "aa" | grep -E "a+"
echo "" | grep -E "a*"
echo "aaa" | grep -E "a{3}"
echo "aa" | grep -E "a{1,3}"
echo "aaaa" | grep -E "a{2,}"
```

## 2 grep与正则表达式

### 2.1 grep高级用法

#### 2.1.1 基本grep模式

```bash
#!/bin/bash
# grep正则表达式示例

# 搜索文件中的模式
grep "root" /etc/passwd
grep -i "ROOT" /etc/passwd  # 忽略大小写
grep -v "nologin" /etc/passwd  # 反向匹配
grep -w "root" /etc/passwd     # 整词匹配
grep -n "root" /etc/passwd     # 显示行号
grep -c "root" /etc/passwd     # 计数

# 使用正则表达式
grep "^[a-z]" /etc/passwd      # 以小写字母开头
grep "bash$" /etc/passwd       # 以bash结尾
grep "^root:" /etc/passwd      # 以root:开头
grep ".*:.*:.*:.*:" /etc/passwd  # 匹配多个冒号
```

#### 2.1.2 扩展正则表达式

```bash
#!/bin/bash
# 扩展正则表达式示例

# 使用egrep或grep -E
egrep "root|admin" /etc/passwd
grep -E "root|admin" /etc/passwd

# 匹配IP地址
grep -E "[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}" /etc/hosts

# 匹配邮箱地址
grep -E "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}" /etc/passwd

# 匹配日期格式
grep -E "[0-9]{4}-[0-9]{2}-[0-9]{2}" /var/log/syslog
```

### 2.2 实际应用案例

#### 2.2.1 日志分析

```bash
#!/bin/bash
# 日志分析正则表达式

# 分析Apache访问日志
LOG_FILE="/var/log/apache2/access.log"

# 统计404错误
echo "404错误统计:"
grep " 404 " "$LOG_FILE" | wc -l

# 找出访问最多的IP
echo "访问最多的IP:"
grep -oE "[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}" "$LOG_FILE" |
sort | uniq -c | sort -nr | head -10

# 分析用户代理
echo "常见用户代理:"
grep -oE '"[^"]*" "[^"]*" "[^"]*"' "$LOG_FILE" |
sed 's/.*"\([^"]*\)"$/\1/' |
sort | uniq -c | sort -nr | head -5

# 分析请求路径
echo "访问最多的路径:"
grep -oE '"GET [^ ]*' "$LOG_FILE" |
sed 's/"GET //' |
sort | uniq -c | sort -nr | head -10
```

#### 2.2.2 系统监控

```bash
#!/bin/bash
# 系统监控正则表达式

# 检查系统信息
echo "=== 系统信息 ==="

# 提取CPU信息
echo "CPU信息:"
grep "model name" /proc/cpuinfo | 
    sed 's/.*: //' | 
    head -1

# 提取内存信息
echo "内存信息:"
grep "MemTotal" /proc/meminfo | 
    sed 's/.*: \([0-9]*\) kB/\1 KB/'

# 检查磁盘使用
echo "磁盘使用:"
df -h | 
    grep -E '^/dev/' |
    awk '{print $1 ": " $5 " used"}'

# 检查网络接口
echo "网络接口:"
ip addr show | 
    grep -E '^[0-9]:' |
    sed 's/.*: \([^:]*\):.*/\1/'
```

## 3 sed与正则表达式

### 3.1 sed基础用法

#### 3.1.1 基本替换

```bash
#!/bin/bash
# sed替换示例

# 简单替换
echo "hello world" | sed 's/world/linux/'

# 全局替换
echo "hello world world" | sed 's/world/linux/g'

# 指定行替换
echo -e "line1\nline2\nline3" | sed '2s/line/LINE/'

# 使用正则表达式
echo "user:1234:5678" | sed 's/[0-9]*/NUMBER/g'

# 反向引用
echo "hello world" | sed 's/\(.*\) \(world\)/\2 \1/'
```

#### 3.1.2 高级sed技巧

```bash
#!/bin/bash
# 高级sed技巧

# 删除匹配行
echo -e "line1\nline2\nline3" | sed '/line2/d'

# 打印匹配行
echo -e "line1\nline2\nline3" | sed -n '/line2/p'

# 多重替换
echo "hello123world456" | sed -e 's/[0-9]/-/g' -e 's/hello/HELLO/g'

# 使用变量
name="world"
echo "hello $name" | sed "s/$name/linux/"

# 就地编辑文件（谨慎使用）
# sed -i 's/old/new/g' filename
```

### 3.2 sed实际应用

#### 3.2.1 配置文件处理

```bash
#!/bin/bash
# 配置文件处理示例

# 更新配置文件
CONFIG_FILE="/etc/nginx/nginx.conf"

# 更新监听端口
sed -i 's/listen 80;/listen 8080;/' "$CONFIG_FILE"

# 添加新配置
sed -i '/server_name localhost;/a \\tlocation /api {\\n\\t\\tproxy_pass http://backend;\\n\\t}' "$CONFIG_FILE"

# 注释掉某些配置
sed -i '/location\/old/s/^/#/' "$CONFIG_FILE"

# 取消注释
sed -i '/^#.*location\/new/s/^#//' "$CONFIG_FILE"
```

#### 3.2.2 日志处理

```bash
#!/bin/bash
# 日志处理示例

# 清理日志文件
LOG_FILE="/var/log/application.log"

# 移除IP地址信息
sed -i 's/[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}/[IP-REDACTED]/g' "$LOG_FILE"

# 标准化时间格式
sed -i 's/\([0-9]\{4\}-[0-9]\{2\}-[0-9]\{2\}\) \([0-9]\{2\}:[0-9]\{2\}:[0-9]\{2\}\)/\1T\2Z/g' "$LOG_FILE"

# 提取错误信息
sed -n '/ERROR/s/.*ERROR: \(.*\)/\1/p' "$LOG_FILE" > errors.txt

# 统计错误类型
sed -n '/ERROR/s/.*ERROR: \([A-Z_]*\).*/\1/p' "$LOG_FILE" |
sort | uniq -c | sort -nr
```

## 4 awk与正则表达式

### 4.1 awk模式匹配

#### 4.1.1 基本模式匹配

```bash
#!/bin/bash
# awk模式匹配示例

# 匹配整行
awk '/root/' /etc/passwd

# 匹配特定字段
awk -F: '$1 ~ /^root$/' /etc/passwd
awk -F: '$3 ~ /^[0-9]+$/' /etc/passwd

# 匹配多个模式
awk -F: '/root|admin/ {print $1}' /etc/passwd

# 使用正则表达式匹配
awk -F: '$1 ~ /^[a-z]/ {print $1, $3}' /etc/passwd

# 范围匹配
awk '/^start_pattern/,/^end_pattern/' filename
```

#### 4.1.2 高级awk正则

```bash
#!/bin/bash
# 高级awk正则示例

# 匹配IP地址
awk '$0 ~ /[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}/ {print $0}' access.log

# 匹配邮箱
awk '$0 ~ /[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/ {print $0}' emails.txt

# 匹配日期
awk '$0 ~ /[0-9]{4}-[0-9]{2}-[0-9]{2}/ {print $0}' logs.txt

# 提取URL
awk 'match($0, /https?:\/\/[^[:space:]]+/) {print substr($0, RSTART, RLENGTH)}' webpage.html
```

### 4.2 awk实际应用

#### 4.2.1 日志分析

```bash
#!/bin/bash
# awk日志分析示例

# 分析Apache日志
LOG_FILE="/var/log/apache2/access.log"

# 统计每个IP的访问次数
awk '{print $1}' "$LOG_FILE" |
sort | uniq -c | sort -nr |
awk '{printf "%-15s %6d\n", $2, $1}'

# 统计状态码
awk '{print $9}' "$LOG_FILE" |
sort | uniq -c | sort -nr |
awk '{printf "状态码 %3s: %6d 次\n", $2, $1}'

# 分析用户代理
awk -F'"' '{print $6}' "$LOG_FILE" |
sort | uniq -c | sort -nr |
head -10 |
awk '{printf "%-50s %6d\n", substr($2,1,50), $1}'

# 计算平均响应时间
awk '$NF ~ /^[0-9]+$/ {sum+=$NF; count++} END {printf "平均响应时间: %.2fms\n", sum/count}' "$LOG_FILE"
```

#### 4.2.2 系统监控

```bash
#!/bin/bash
# awk系统监控示例

# 监控进程
ps aux |
awk 'NR>1 && $3 > 10 {printf "%-20s %8.1f%%\n", $11, $3}' |
sort -k2 -nr

# 监控磁盘使用
df -h |
awk 'NR>1 && $5+0 > 80 {printf "%-20s %6s 已满\n", $1, $5}'

# 监控网络连接
netstat -tuln |
awk 'NR>2 {printf "%-8s %-22s %-10s\n", $1, $4, $6}'

# 监控系统负载
uptime |
awk -F'load average:' '{printf "1分钟负载: %s\n5分钟负载: %s\n15分钟负载: %s\n", $2, $3, $4}' |
awk '{print $3, $4, $5}'
```

## 5 正则表达式调试技巧

### 5.1 调试工具

#### 5.1.1 使用grep调试

```bash
#!/bin/bash
# grep调试技巧

# 启用颜色高亮
export GREP_OPTIONS='--color=auto'

# 显示匹配位置
grep -n "pattern" filename

# 显示上下文
grep -C 3 "pattern" filename

# 仅显示匹配部分
grep -o "pattern" filename

# 使用调试模式
echo "test123" | grep -E "test[0-9]+"
```

#### 5.1.2 使用在线工具

```bash
#!/bin/bash
# 正则表达式测试脚本

test_regex() {
    local pattern="$1"
    local test_string="$2"
    
    echo "测试正则表达式: $pattern"
    echo "测试字符串: $test_string"
    echo
    
    if [[ "$test_string" =~ $pattern ]]; then
        echo "✅ 匹配成功"
        echo "匹配结果: ${BASH_REMATCH[0]}"
        if [ ${#BASH_REMATCH[@]} -gt 1 ]; then
            for i in $(seq 1 $((${#BASH_REMATCH[@]}-1))); do
                echo "捕获组 $i: ${BASH_REMATCH[$i]}"
            done
        fi
    else
        echo "❌ 匹配失败"
    fi
}

# 测试示例
test_regex "[0-9]+" "test123"
test_regex "([a-z]+)@([a-z]+)\.com" "user@example.com"
```

### 5.2 性能优化

#### 5.2.1 优化正则表达式

```bash
#!/bin/bash
# 正则表达式优化示例

# 避免回溯
# 慢
awk '/.*a.*b.*c/' filename
# 快
awk '/a.*b.*c/' filename

# 使用锚点
# 慢
grep "pattern" filename
# 快
grep "^pattern" filename

# 使用字符类
# 慢
grep "[0123456789]" filename
# 快
grep "[0-9]" filename

# 避免嵌套量词
# 慢
awk '/(a+)+/' filename
# 快
awk '/a+/' filename
```

#### 5.2.2 批量处理优化

```bash
#!/bin/bash
# 批量处理优化

# 使用grep的批量处理
# 慢
for file in *.log; do
    grep "ERROR" "$file"
done

# 快
grep "ERROR" *.log

# 使用awk处理大文件
# 慢
while IFS= read -r line; do
    if [[ "$line" =~ pattern ]]; then
        echo "$line"
    fi
done < bigfile.txt

# 快
awk '/pattern/' bigfile.txt
```

## 6 综合实例

### 6.1 完整日志分析系统

```bash
#!/bin/bash
# 完整日志分析系统

# 配置文件
LOG_DIR="/var/log"
REPORT_DIR="/tmp/log_analysis"
RETENTION_DAYS=7

# 创建报告目录
mkdir -p "$REPORT_DIR"

# 分析函数
analyze_system_logs() {
    local report_file="$REPORT_DIR/system_analysis_$(date +%Y%m%d_%H%M%S).txt"
    
    {
        echo "=== 系统日志分析报告 ==="
        echo "生成时间: $(date)"
        echo "主机: $(hostname)"
        echo ""
        
        # 分析认证日志
        if [ -f "/var/log/auth.log" ]; then
            echo "=== 认证日志分析 ==="
            echo "SSH失败登录:"
            grep "Failed password" /var/log/auth.log |
            awk '{print $11}' |
            sort | uniq -c | sort -nr |
            head -10 |
            awk '{printf "%-15s %6d 次\n", $2, $1}'
            echo ""
        fi
        
        # 分析系统日志
        if [ -f "/var/log/syslog" ]; then
            echo "=== 系统日志分析 ==="
            echo "错误级别统计:"
            grep -E "(ERROR|CRITICAL|FATAL)" /var/log/syslog |
            awk '{print $5}' |
            sort | uniq -c | sort -nr |
            awk '{printf "%-15s %6d 次\n", $2, $1}'
            echo ""
        fi
        
        # 分析内核日志
        if [ -f "/var/log/kern.log" ]; then
            echo "=== 内核日志分析 ==="
            echo "内核错误:"
            grep "error" /var/log/kern.log |
            tail -5
            echo ""
        fi
    } > "$report_file"
    
    echo "系统日志分析报告: $report_file"
}

# Web日志分析
analyze_web_logs() {
    local report_file="$REPORT_DIR/web_analysis_$(date +%Y%m%d_%H%M%S).txt"
    
    # 查找Web日志文件
    local web_logs=(
        "/var/log/apache2/access.log"
        "/var/log/nginx/access.log"
        "/var/log/lighttpd/access.log"
    )
    
    for log_file in "${web_logs[@]}"; do
        if [ -f "$log_file" ]; then
            {
                echo "=== Web日志分析: $log_file ==="
                echo ""
                
                # 基本统计
                echo "总请求数: $(wc -l < "$log_file")"
                echo "独立IP数: $(awk '{print $1}' "$log_file" | sort | uniq | wc -l)"
                echo ""
                
                # 状态码分析
                echo "状态码统计:"
                awk '{print $9}' "$log_file" |
                sort | uniq -c | sort -nr |
                awk '{printf "状态码 %3s: %6d 次\n", $2, $1}'
                echo ""
                
                # 访问最多的IP
                echo "访问最多的IP:"
                awk '{print $1}' "$log_file" |
                sort | uniq -c | sort -nr |
                head -10 |
                awk '{printf "%-15s %6d 次\n", $2, $1}'
                echo ""
                
                # 错误请求
                echo "错误请求 (4xx, 5xx):"
                awk '$9 >= 400 {print $1, $7, $9}' "$log_file" |
                sort | uniq -c | sort -nr |
                head -10 |
                awk '{printf "%-15s %-30s %3s 次\n", $2, $3, $1}'
            } > "$report_file"
            
            echo "Web日志分析报告: $report_file"
        fi
    done
}

# 清理旧报告
cleanup_reports() {
    find "$REPORT_DIR" -name "*.txt" -mtime +$RETENTION_DAYS -delete
    echo "已清理旧报告"
}

# 主程序
main() {
    analyze_system_logs
    analyze_web_logs
    cleanup_reports
    
    echo "日志分析完成，报告保存在: $REPORT_DIR"
}

# 运行主程序
main "$@"
```

这些示例展示了正则表达式在Linux系统中的各种应用场景，从基本的模式匹配到复杂的日志分析，掌握这些技能可以大大提高文本处理的效率。