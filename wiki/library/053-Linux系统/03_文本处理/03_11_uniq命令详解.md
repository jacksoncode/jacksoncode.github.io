# 03_11_uniq命令详解

## 1. 命令概述

`uniq` 命令是Linux系统中用于处理文本文件中重复行的工具。它可以检测并去除文件中的重复行，显示唯一的行或只显示重复的行。`uniq`命令通常与`sort`命令配合使用，因为它只能检测相邻的重复行，而无法处理不连续的重复行。

- **去除重复行**：删除文件中的重复行
- **显示重复行**：只显示文件中的重复行
- **统计重复次数**：显示每行的重复次数
- **忽略字段**：可以忽略指定的前导字段进行比较
- **检查字符**：可以只比较指定数量的字符

## 2. 语法格式

`uniq`命令的基本语法格式如下：

```bash
uniq [选项] [输入文件 [输出文件]]
```

其中：
- `[选项]`：可选参数，用于控制去重的方式和行为
- `[输入文件]`：要处理的输入文件，如果不指定则从标准输入读取
- `[输出文件]`：处理结果的输出文件，如果不指定则输出到标准输出

## 3. 常用选项

| 选项 | 说明 | 示例 |
|------|------|------|
| `-c` | 显示每行的出现次数 | `uniq -c file.txt` |
| `-d` | 只显示重复的行 | `uniq -d file.txt` |
| `-u` | 只显示唯一的行（不重复的行） | `uniq -u file.txt` |
| `-i` | 忽略大小写差异 | `uniq -i file.txt` |
| `-f N` | 忽略前N个字段进行比较 | `uniq -f 2 file.txt` |
| `-s N` | 忽略前N个字符进行比较 | `uniq -s 5 file.txt` |
| `-w N` | 只比较每行的前N个字符 | `uniq -w 10 file.txt` |
| `-z` | 使用NUL字符作为行分隔符 | `uniq -z file.txt` |

## 4. 基本用法

### 4.1 去除重复行

**示例1：去除文件中的重复行**

```bash
uniq file.txt
```

此命令将去除文件中相邻的重复行，并将结果输出到标准输出。注意，`uniq`只会去除相邻的重复行，所以通常在使用前需要先排序。

**示例2：去除重复行并保存结果**

```bash
uniq file.txt > unique_file.txt
```

此命令将去除文件中的重复行，并将结果保存到指定文件。

### 4.2 显示重复次数

**示例3：显示每行的重复次数**

```bash
sort file.txt | uniq -c
```

此命令首先对文件内容进行排序，然后显示每行的重复次数，结果将以"次数+空格+内容"的格式输出。

**示例4：显示重复次数并排序**

```bash
sort file.txt | uniq -c | sort -nr
```

此命令组合将显示每行的重复次数，并按次数从高到低排序，常用于统计频率。

### 4.3 只显示重复行或唯一行

**示例5：只显示重复的行**

```bash
sort file.txt | uniq -d
```

此命令将只显示文件中出现过多次的行（重复行）。

**示例6：只显示唯一的行**

```bash
sort file.txt | uniq -u
```

此命令将只显示文件中只出现过一次的行（唯一行）。

## 5. 高级用法与技巧

### 5.1 忽略特定字段

**示例7：忽略前导字段进行比较**

```bash
sort file.txt | uniq -f 2
```

此命令将忽略每行的前2个字段进行比较，只比较剩余部分是否相同。这在处理带有时间戳或序号的日志文件时非常有用。

**示例8：忽略指定字符进行比较**

```bash
sort file.txt | uniq -s 5
```

此命令将忽略每行的前5个字符进行比较，只比较从第6个字符开始的部分是否相同。

### 5.2 只比较特定数量的字符

**示例9：只比较每行的前N个字符**

```bash
sort file.txt | uniq -w 10
```

此命令将只比较每行的前10个字符，如果前10个字符相同，则认为两行相同。

**示例10：忽略字段并只比较特定字符**

```bash
sort file.txt | uniq -f 1 -w 8
```

此命令将忽略每行的第1个字段，然后只比较接下来的8个字符，这在处理特定格式的日志文件时非常有用。

### 5.3 大小写不敏感的比较

**示例11：忽略大小写差异进行比较**

```bash
sort file.txt | uniq -i
```

此命令将忽略大小写差异，将大写和小写字母视为相同进行比较。

### 5.4 组合多个选项

**示例12：组合多个选项进行复杂比较**

```bash
sort file.txt | uniq -ci -f 2 -w 10
```

此命令将忽略大小写差异，忽略前2个字段，只比较接下来的10个字符，并显示每行的重复次数。

## 6. 实用技巧

### 6.1 统计单词频率

**示例13：统计文件中单词出现的频率**

```bash
cat file.txt | tr -s '[:space:]' '\n' | sort | uniq -c | sort -nr
```

此命令组合首先将文件内容中的空白字符替换为换行符，然后排序、去重并计数，最后按计数从高到低排序，用于统计文件中单词出现的频率。

**示例14：统计特定模式的频率**

```bash
grep 'pattern' file.txt | sort | uniq -c | sort -nr
```

此命令组合首先过滤出包含特定模式的行，然后排序、去重并计数，最后按计数从高到低排序，用于统计特定模式出现的频率。

### 6.2 查找日志中的唯一IP地址

**示例15：从日志文件中提取唯一IP地址**

```bash
grep -o '[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}' access.log | sort | uniq
```

此命令组合首先使用正则表达式从日志文件中提取IP地址，然后排序并去重，得到所有唯一的IP地址。

**示例16：统计IP地址访问次数**

```bash
grep -o '[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}' access.log | sort | uniq -c | sort -nr
```

此命令组合在提取IP地址后，还统计了每个IP地址的访问次数，并按访问次数从高到低排序。

### 6.3 查找配置文件中的唯一值

**示例17：从配置文件中提取唯一的配置项**

```bash
grep '^option' config.txt | sort | uniq
```

此命令组合首先过滤出以"option"开头的配置行，然后排序并去重，得到所有唯一的配置项。

### 6.4 检测文件中的重复行

**示例18：检测并显示文件中的重复行及其出现次数**

```bash
sort file.txt | uniq -d | xargs -I {} grep -c '{}' file.txt
```

此命令组合首先找到文件中的重复行，然后统计每行出现的次数。

### 6.5 生成唯一ID列表

**示例19：从文件中生成唯一ID列表**

```bash
grep 'ID:' data.txt | cut -d: -f2 | sort | uniq > unique_ids.txt
```

此命令组合首先过滤出包含"ID:"的行，然后提取ID值，最后排序并去重，生成唯一ID列表。

## 7. 常见问题与解决方案

### 7.1 无法去除不连续的重复行

**问题：** `uniq`命令无法去除文件中不连续的重复行
**解决方案：** 在使用`uniq`命令之前先使用`sort`命令对文件进行排序

```bash
sort file.txt | uniq
```

### 7.2 比较时大小写敏感

**问题：** `uniq`命令在比较时区分大小写
**解决方案：** 使用`-i`选项忽略大小写差异

```bash
sort file.txt | uniq -i
```

### 7.3 处理大文件时性能问题

**问题：** 处理大文件时，`sort | uniq`组合命令执行速度慢
**解决方案：** 增加系统资源或拆分文件处理，也可以使用更高效的工具如`awk`

```bash
awk '!seen[$0]++' file.txt
```

### 7.4 只比较部分字段时出现问题

**问题：** 使用`-f`或`-s`选项时结果不符合预期
**解决方案：** 确保理解字段和字符的计数方式，并正确设置参数值

```bash
sort file.txt | uniq -f 1 -s 2
```

### 7.5 与其他命令结合使用时的问题

**问题：** 在管道中与其他命令结合使用时出现问题
**解决方案：** 确保数据在管道中的流动是正确的，可以使用中间文件进行调试

```bash
sort file.txt > sorted.txt
uniq sorted.txt > unique.txt
```

## 8. 相关命令对比

| 命令 | 主要特点 | 适用场景 |
|------|---------|---------|
| `uniq` | 去除相邻重复行，需要先排序 | 与sort配合使用，用于去重和统计 |
| `sort` | 对文本行进行排序，支持多种排序方式 | 文本排序、字段排序、为uniq做准备 |
| `comm` | 比较两个已排序的文件 | 查找共同行和独有行 |
| `diff` | 比较文件的差异 | 查找文件间的不同之处 |
| `awk` | 强大的文本处理工具，也可以去重 | 更复杂的文本处理和去重需求 |
| `perl` | 编程语言，可用于复杂的文本处理 | 高度自定义的文本处理任务 |

## 9. 实践练习

### 9.1 基础练习

1. 对一个文本文件进行排序并去重
2. 统计文本文件中每行的重复次数
3. 只显示文本文件中的唯一行或重复行

### 9.2 中级练习

1. 统计文本文件中单词出现的频率
2. 从日志文件中提取唯一的IP地址
3. 使用`uniq`命令忽略特定字段进行比较

### 9.3 高级练习

1. 编写脚本，分析Web服务器日志，统计访问最频繁的10个IP地址
2. 实现一个简单的拼写检查工具，找出文本中重复的单词
3. 结合`find`、`sort`和`uniq`命令，查找系统中重复的文件

## 10. 总结

`uniq`命令是Linux系统中一个专门用于处理文本文件中重复行的工具，它通常与`sort`命令配合使用，用于去除重复行、统计行出现次数、查找唯一行或重复行等任务。`uniq`命令支持多种选项，可以根据需要忽略特定字段或字符，进行大小写不敏感的比较，以及只比较特定数量的字符。

通过掌握`uniq`命令的基本用法和高级技巧，并与其他文本处理命令结合使用，用户可以更高效地处理和分析文本数据，解决各种实际问题。无论是在日常文件管理、系统管理还是数据处理工作中，`uniq`命令都是一个不可或缺的工具。