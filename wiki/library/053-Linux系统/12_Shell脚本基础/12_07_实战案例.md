# Shell脚本实战案例

## 1 系统监控脚本

### 1.1 综合系统监控

```bash
#!/bin/bash
# 系统监控综合脚本
# 功能：监控CPU、内存、磁盘、网络等系统资源

# 配置文件
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
CONFIG_FILE="$SCRIPT_DIR/system_monitor.conf"
LOG_DIR="/var/log/system_monitor"
ALERT_EMAIL="admin@example.com"

# 默认配置
DEFAULT_CPU_THRESHOLD=80
DEFAULT_MEM_THRESHOLD=85
DEFAULT_DISK_THRESHOLD=90
DEFAULT_NETWORK_THRESHOLD=1000  # MB
DEFAULT_CHECK_INTERVAL=300      # 5分钟

# 颜色定义
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
NC='\033[0m'

# 加载配置
load_config() {
    if [ -f "$CONFIG_FILE" ]; then
        source "$CONFIG_FILE"
    else
        CPU_THRESHOLD=$DEFAULT_CPU_THRESHOLD
        MEM_THRESHOLD=$DEFAULT_MEM_THRESHOLD
        DISK_THRESHOLD=$DEFAULT_DISK_THRESHOLD
        NETWORK_THRESHOLD=$DEFAULT_NETWORK_THRESHOLD
        CHECK_INTERVAL=$DEFAULT_CHECK_INTERVAL
    fi
}

# 日志函数
log() {
    local level="$1"
    local message="$2"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    local log_file="$LOG_DIR/monitor_$(date +%Y%m%d).log"
    
    mkdir -p "$LOG_DIR"
    echo "[$timestamp] [$level] $message" | tee -a "$log_file"
}

# 发送告警邮件
send_alert() {
    local subject="$1"
    local body="$2"
    
    if command -v mail >/dev/null 2>&1; then
        echo "$body" | mail -s "$subject" "$ALERT_EMAIL"
        log "INFO" "告警邮件已发送: $subject"
    else
        log "WARN" "mail命令不可用，无法发送告警邮件"
    fi
}

# 检查CPU使用率
check_cpu() {
    local cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)
    cpu_usage=${cpu_usage%.*}  # 去除小数部分
    
    if [ "$cpu_usage" -gt "$CPU_THRESHOLD" ]; then
        log "WARN" "CPU使用率过高: ${cpu_usage}% (阈值: ${CPU_THRESHOLD}%)"
        send_alert "CPU告警" "服务器CPU使用率过高: ${cpu_usage}%"
        return 1
    else
        log "INFO" "CPU使用率正常: ${cpu_usage}%"
        return 0
    fi
}

# 检查内存使用率
check_memory() {
    local mem_info=$(free | grep Mem)
    local total=$(echo $mem_info | awk '{print $2}')
    local used=$(echo $mem_info | awk '{print $3}')
    local mem_usage=$((used * 100 / total))
    
    if [ "$mem_usage" -gt "$MEM_THRESHOLD" ]; then
        log "WARN" "内存使用率过高: ${mem_usage}% (阈值: ${MEM_THRESHOLD}%)"
        send_alert "内存告警" "服务器内存使用率过高: ${mem_usage}%"
        return 1
    else
        log "INFO" "内存使用率正常: ${mem_usage}%"
        return 0
    fi
}

# 检查磁盘使用率
check_disk() {
    local disk_issues=0
    
    while read filesystem size used avail usage mountpoint; do
        if [[ "$filesystem" =~ ^/dev/ ]]; then
            usage_num=${usage%?}  # 去除%
            if [ "$usage_num" -gt "$DISK_THRESHOLD" ]; then
                log "WARN" "磁盘使用率过高: $mountpoint ${usage} (阈值: ${DISK_THRESHOLD}%)"
                send_alert "磁盘告警" "磁盘 $mountpoint 使用率过高: ${usage}"
                disk_issues=$((disk_issues + 1))
            else
                log "INFO" "磁盘使用率正常: $mountpoint ${usage}"
            fi
        fi
    done < <(df -h | grep -E '^/dev/')
    
    return $disk_issues
}

# 检查网络流量
check_network() {
    local interface=$(ip route | grep default | awk '{print $5}' | head -1)
    
    if [ -z "$interface" ]; then
        log "WARN" "无法确定默认网络接口"
        return 1
    fi
    
    # 获取网络接口统计信息
    local rx_before=$(cat /sys/class/net/$interface/statistics/rx_bytes)
    local tx_before=$(cat /sys/class/net/$interface/statistics/tx_bytes)
    
    sleep 1
    
    local rx_after=$(cat /sys/class/net/$interface/statistics/rx_bytes)
    local tx_after=$(cat /sys/class/net/$interface/statistics/tx_bytes)
    
    local rx_rate=$(((rx_after - rx_before) * 8 / 1024 / 1024))  # Mbps
    local tx_rate=$(((tx_after - tx_before) * 8 / 1024 / 1024))  # Mbps
    local total_rate=$((rx_rate + tx_rate))
    
    if [ "$total_rate" -gt "$NETWORK_THRESHOLD" ]; then
        log "WARN" "网络流量过高: ${total_rate}Mbps (阈值: ${NETWORK_THRESHOLD}Mbps)"
        send_alert "网络告警" "网络流量过高: ${total_rate}Mbps"
        return 1
    else
        log "INFO" "网络流量正常: ${total_rate}Mbps"
        return 0
    fi
}

# 检查进程状态
check_processes() {
    local critical_processes=("sshd" "nginx" "mysql")
    local issues=0
    
    for process in "${critical_processes[@]}"; do
        if ! pgrep -f "$process" >/dev/null 2>&1; then
            log "ERROR" "关键进程未运行: $process"
            send_alert "进程告警" "关键进程未运行: $process"
            issues=$((issues + 1))
        else
            log "INFO" "进程运行正常: $process"
        fi
    done
    
    return $issues
}

# 生成系统报告
generate_report() {
    local report_file="$LOG_DIR/system_report_$(date +%Y%m%d_%H%M%S).txt"
    
    {
        echo "=== 系统监控报告 ==="
        echo "生成时间: $(date)"
        echo "主机名: $(hostname)"
        echo ""
        
        echo "=== CPU信息 ==="
        echo "CPU使用率: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}')"
        echo "CPU核心数: $(nproc)"
        echo "CPU型号: $(grep 'model name' /proc/cpuinfo | head -1 | cut -d: -f2 | xargs)"
        echo ""
        
        echo "=== 内存信息 ==="
        free -h
        echo ""
        
        echo "=== 磁盘信息 ==="
        df -h
        echo ""
        
        echo "=== 网络信息 ==="
        ip addr show
        echo ""
        
        echo "=== 进程信息 ==="
        ps aux | head -20
        echo ""
        
        echo "=== 系统负载 ==="
        uptime
        echo ""
        
        echo "=== 网络连接 ==="
        netstat -tuln | head -20
    } > "$report_file"
    
    log "INFO" "系统报告已生成: $report_file"
    echo "$report_file"
}

# 主监控循环
monitor_loop() {
    log "INFO" "系统监控已启动"
    
    while true; do
        log "INFO" "开始系统检查..."
        
        check_cpu
        check_memory
        check_disk
        check_network
        check_processes
        
        log "INFO" "系统检查完成，等待下一次检查..."
        sleep "$CHECK_INTERVAL"
    done
}

# 显示帮助信息
show_help() {
    cat << EOF
系统监控脚本

使用方法: $0 [选项]

选项:
    start    启动监控服务
    stop     停止监控服务
    status   查看监控状态
    report   生成系统报告
    help     显示帮助信息

配置文件: $CONFIG_FILE
日志目录: $LOG_DIR
EOF
}

# 启动监控服务
start_monitor() {
    local pid_file="/var/run/system_monitor.pid"
    
    if [ -f "$pid_file" ]; then
        local pid=$(cat "$pid_file")
        if kill -0 "$pid" 2>/dev/null; then
            echo "监控服务已在运行 (PID: $pid)"
            return 1
        fi
    fi
    
    echo "启动系统监控服务..."
    nohup "$0" monitor > /dev/null 2>&1 &
    echo $! > "$pid_file"
    echo "监控服务已启动 (PID: $!)"
}

# 停止监控服务
stop_monitor() {
    local pid_file="/var/run/system_monitor.pid"
    
    if [ -f "$pid_file" ]; then
        local pid=$(cat "$pid_file")
        if kill -0 "$pid" 2>/dev/null; then
            kill "$pid"
            rm -f "$pid_file"
            echo "监控服务已停止"
        else
            echo "监控服务未运行"
            rm -f "$pid_file"
        fi
    else
        echo "监控服务未运行"
    fi
}

# 显示监控状态
show_status() {
    local pid_file="/var/run/system_monitor.pid"
    
    if [ -f "$pid_file" ]; then
        local pid=$(cat "$pid_file")
        if kill -0 "$pid" 2>/dev/null; then
            echo "监控服务运行中 (PID: $pid)"
            echo "配置文件: $CONFIG_FILE"
            echo "日志目录: $LOG_DIR"
        else
            echo "监控服务未运行 (PID文件存在但进程不存在)"
        fi
    else
        echo "监控服务未运行"
    fi
}

# 主程序
main() {
    load_config
    
    case "${1:-help}" in
        start)
            start_monitor
            ;;
        stop)
            stop_monitor
            ;;
        status)
            show_status
            ;;
        monitor)
            monitor_loop
            ;;
        report)
            generate_report
            ;;
        help|*)
            show_help
            ;;
    esac
}

# 运行主程序
main "$@"
```

## 2 自动化部署脚本

### 2.1 Web应用部署脚本

```bash
#!/bin/bash
# Web应用自动化部署脚本
# 功能：自动部署Web应用到服务器

# 配置变量
APP_NAME="mywebapp"
APP_VERSION="1.0.0"
DEPLOY_USER="deploy"
DEPLOY_DIR="/var/www/$APP_NAME"
BACKUP_DIR="/var/backups/$APP_NAME"
REPO_URL="https://github.com/example/mywebapp.git"
BRANCH="main"

# 颜色输出
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# 日志函数
log() {
    local level="$1"
    shift
    local message="$*"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    case "$level" in
        INFO)
            echo -e "${GREEN}[INFO]${NC} $timestamp - $message"
            ;;
        WARN)
            echo -e "${YELLOW}[WARN]${NC} $timestamp - $message"
            ;;
        ERROR)
            echo -e "${RED}[ERROR]${NC} $timestamp - $message"
            ;;
        *)
            echo "[$timestamp] [$level] $message"
            ;;
    esac
}

# 检查运行环境
check_environment() {
    log "INFO" "检查运行环境..."
    
    # 检查必需命令
    local required_commands=("git" "npm" "pm2" "nginx")
    for cmd in "${required_commands[@]}"; do
        if ! command -v "$cmd" >/dev/null 2>&1; then
            log "ERROR" "缺少必需命令: $cmd"
            exit 1
        fi
    done
    
    # 检查目录权限
    if [ ! -d "$DEPLOY_DIR" ]; then
        mkdir -p "$DEPLOY_DIR"
    fi
    
    if [ ! -w "$DEPLOY_DIR" ]; then
        log "ERROR" "无写入权限: $DEPLOY_DIR"
        exit 1
    fi
    
    log "INFO" "环境检查通过"
}

# 创建备份
create_backup() {
    log "INFO" "创建应用备份..."
    
    if [ -d "$DEPLOY_DIR" ]; then
        local backup_name="${APP_NAME}_$(date +%Y%m%d_%H%M%S)"
        local backup_path="$BACKUP_DIR/$backup_name"
        
        mkdir -p "$BACKUP_DIR"
        
        if tar -czf "$backup_path.tar.gz" -C "$(dirname "$DEPLOY_DIR")" "$APP_NAME" 2>/dev/null; then
            log "INFO" "备份创建成功: $backup_path.tar.gz"
            echo "$backup_path.tar.gz"
        else
            log "ERROR" "备份创建失败"
            exit 1
        fi
    else
        log "INFO" "首次部署，无需备份"
    fi
}

# 拉取代码
pull_code() {
    log "INFO" "拉取最新代码..."
    
    local temp_dir=$(mktemp -d)
    
    if git clone -b "$BRANCH" "$REPO_URL" "$temp_dir" >/dev/null 2>&1; then
        log "INFO" "代码拉取成功"
        echo "$temp_dir"
    else
        log "ERROR" "代码拉取失败"
        rm -rf "$temp_dir"
        exit 1
    fi
}

# 安装依赖
install_dependencies() {
    local source_dir="$1"
    
    log "INFO" "安装依赖..."
    
    cd "$source_dir"
    
    if [ -f "package.json" ]; then
        if npm install --production >/dev/null 2>&1; then
            log "INFO" "依赖安装成功"
        else
            log "ERROR" "依赖安装失败"
            exit 1
        fi
    else
        log "WARN" "未找到package.json文件"
    fi
}

# 构建应用
build_application() {
    local source_dir="$1"
    
    log "INFO" "构建应用..."
    
    cd "$source_dir"
    
    if [ -f "package.json" ]; then
        local build_script=$(grep '"build"' package.json)
        if [ -n "$build_script" ]; then
            if npm run build >/dev/null 2>&1; then
                log "INFO" "应用构建成功"
            else
                log "ERROR" "应用构建失败"
                exit 1
            fi
        else
            log "INFO" "无需构建步骤"
        fi
    fi
}

# 运行测试
run_tests() {
    local source_dir="$1"
    
    log "INFO" "运行测试..."
    
    cd "$source_dir"
    
    if [ -f "package.json" ]; then
        local test_script=$(grep '"test"' package.json)
        if [ -n "$test_script" ]; then
            if npm test >/dev/null 2>&1; then
                log "INFO" "测试通过"
            else
                log "ERROR" "测试失败"
                exit 1
            fi
        else
            log "INFO" "无测试脚本"
        fi
    fi
}

# 部署应用
deploy_application() {
    local source_dir="$1"
    
    log "INFO" "部署应用..."
    
    # 停止现有应用
    if pm2 list | grep -q "$APP_NAME"; then
        log "INFO" "停止现有应用..."
        pm2 stop "$APP_NAME" >/dev/null 2>&1
    fi
    
    # 复制新代码
    if [ -d "$DEPLOY_DIR" ]; then
        rm -rf "$DEPLOY_DIR"/*
    fi
    
    cp -r "$source_dir"/* "$DEPLOY_DIR/"
    
    # 启动应用
    cd "$DEPLOY_DIR"
    
    if [ -f "package.json" ]; then
        local start_script=$(grep '"start"' package.json)
        if [ -n "$start_script" ]; then
            if pm2 start npm --name "$APP_NAME" -- start >/dev/null 2>&1; then
                log "INFO" "应用启动成功"
            else
                log "ERROR" "应用启动失败"
                exit 1
            fi
        else
            log "WARN" "未找到启动脚本"
        fi
    fi
}

# 配置Nginx
configure_nginx() {
    log "INFO" "配置Nginx..."
    
    local nginx_conf="/etc/nginx/sites-available/$APP_NAME"
    local nginx_link="/etc/nginx/sites-enabled/$APP_NAME"
    
    cat > "$nginx_conf" << EOF
server {
    listen 80;
    server_name yourdomain.com;
    
    location / {
        proxy_pass http://localhost:3000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade \$http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto \$scheme;
        proxy_cache_bypass \$http_upgrade;
    }
    
    location /static {
        alias $DEPLOY_DIR/public;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
EOF
    
    if [ ! -L "$nginx_link" ]; then
        ln -s "$nginx_conf" "$nginx_link"
    fi
    
    if nginx -t >/dev/null 2>&1; then
        systemctl reload nginx
        log "INFO" "Nginx配置成功"
    else
        log "ERROR" "Nginx配置测试失败"
        exit 1
    fi
}

# 健康检查
health_check() {
    log "INFO" "执行健康检查..."
    
    local max_attempts=30
    local attempt=1
    
    while [ $attempt -le $max_attempts ]; do
        if curl -f http://localhost:3000/health >/dev/null 2>&1; then
            log "INFO" "健康检查通过"
            return 0
        fi
        
        log "INFO" "等待应用启动... ($attempt/$max_attempts)"
        sleep 2
        attempt=$((attempt + 1))
    done
    
    log "ERROR" "健康检查失败"
    return 1
}

# 清理临时文件
cleanup() {
    local temp_dir="$1"
    
    if [ -d "$temp_dir" ]; then
        rm -rf "$temp_dir"
        log "INFO" "临时文件已清理"
    fi
}

# 回滚功能
rollback() {
    local backup_file="$1"
    
    if [ -f "$backup_file" ]; then
        log "INFO" "开始回滚..."
        
        # 停止应用
        pm2 stop "$APP_NAME" >/dev/null 2>&1
        
        # 恢复备份
        if tar -xzf "$backup_file" -C "$(dirname "$DEPLOY_DIR")"; then
            log "INFO" "回滚成功"
            pm2 start "$APP_NAME" >/dev/null 2>&1
        else
            log "ERROR" "回滚失败"
            exit 1
        fi
    else
        log "ERROR" "备份文件不存在"
        exit 1
    fi
}

# 主部署流程
main() {
    local action="${1:-deploy}"
    
    case "$action" in
        deploy)
            check_environment
            
            local backup_file=$(create_backup)
            local temp_dir=$(pull_code)
            
            install_dependencies "$temp_dir"
            build_application "$temp_dir"
            run_tests "$temp_dir"
            deploy_application "$temp_dir"
            configure_nginx
            
            if health_check; then
                cleanup "$temp_dir"
                log "INFO" "部署成功完成"
            else
                log "ERROR" "部署失败，开始回滚..."
                if [ -n "$backup_file" ]; then
                    rollback "$backup_file"
                fi
                exit 1
            fi
            ;;
        rollback)
            local backup_file="$2"
            if [ -z "$backup_file" ]; then
                echo "请指定备份文件路径"
                exit 1
            fi
            rollback "$backup_file"
            ;;
        *)
            echo "使用方法: $0 {deploy|rollback}"
            exit 1
            ;;
    esac
}

# 运行主程序
main "$@"
```

## 3 日志分析脚本

### 3.1 多日志文件分析

```bash
#!/bin/bash
# 多日志文件分析脚本
# 功能：分析多个日志文件，生成统计报告

# 配置
LOG_DIR="/var/log"
REPORT_DIR="/var/log/analysis"
PATTERNS_FILE="$SCRIPT_DIR/log_patterns.conf"
RETENTION_DAYS=7

# 颜色定义
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# 日志函数
log() {
    local level="$1"
    shift
    local message="$*"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    mkdir -p "$REPORT_DIR"
    echo "[$timestamp] [$level] $message" | tee -a "$REPORT_DIR/analysis.log"
}

# 分析单个日志文件
analyze_log_file() {
    local log_file="$1"
    local report_file="$2"
    
    if [ ! -f "$log_file" ]; then
        log "WARN" "日志文件不存在: $log_file"
        return 1
    fi
    
    local filename=$(basename "$log_file")
    
    {
        echo "=== 日志分析报告: $filename ==="
        echo "分析时间: $(date)"
        echo "文件大小: $(du -h "$log_file" | cut -f1)"
        echo "总行数: $(wc -l < "$log_file")"
        echo ""
        
        # 错误统计
        echo "=== 错误统计 ==="
        echo "ERROR级别: $(grep -c "ERROR" "$log_file" || echo 0)"
        echo "WARN级别: $(grep -c "WARN" "$log_file" || echo 0)"
        echo "CRITICAL级别: $(grep -c "CRITICAL" "$log_file" || echo 0)"
        echo "FATAL级别: $(grep -c "FATAL" "$log_file" || echo 0)"
        echo ""
        
        # 时间分布
        echo "=== 时间分布 ==="
        echo "按小时统计:"
        awk '{print $1, $2}' "$log_file" | cut -d: -f1,2 | sort | uniq -c | sort -nr | head -10
        echo ""
        
        # IP地址统计
        echo "=== IP地址统计 ==="
        echo "访问最多的IP地址:"
        grep -oE '\b([0-9]{1,3}\.){3}[0-9]{1,3}\b' "$log_file" | sort | uniq -c | sort -nr | head -10
        echo ""
        
        # 错误详情
        echo "=== 错误详情 ==="
        echo "最近10个错误:"
        grep "ERROR" "$log_file" | tail -10
        echo ""
        
        # 响应时间分析
        echo "=== 响应时间分析 ==="
        if grep -q "response_time" "$log_file"; then
            echo "平均响应时间:"
            grep "response_time" "$log_file" | awk -F'response_time=' '{print $2}' | awk '{sum+=$1; count++} END {if(count>0) print sum/count "ms"; else print "无数据"}'
        fi
    } > "$report_file"
}

# 分析Web服务器日志
analyze_web_logs() {
    local log_dir="$1"
    local report_prefix="$2"
    
    local log_files=(
        "access.log"
        "error.log"
        "nginx_access.log"
        "nginx_error.log"
    )
    
    for log_file in "${log_files[@]}"; do
        local full_path="$log_dir/$log_file"
        if [ -f "$full_path" ]; then
            local report_file="$REPORT_DIR/${report_prefix}_$(basename "$log_file" .log)_$(date +%Y%m%d_%H%M%S).txt"
            analyze_log_file "$full_path" "$report_file"
            log "INFO" "Web日志分析完成: $report_file"
        fi
    done
}

# 分析系统日志
analyze_system_logs() {
    local log_files=(
        "/var/log/syslog"
        "/var/log/auth.log"
        "/var/log/kern.log"
        "/var/log/dmesg"
    )
    
    for log_file in "${log_files[@]}"; do
        if [ -f "$log_file" ]; then
            local report_file="$REPORT_DIR/system_$(basename "$log_file" .log)_$(date +%Y%m%d_%H%M%S).txt"
            analyze_log_file "$log_file" "$report_file"
            log "INFO" "系统日志分析完成: $report_file"
        fi
    done
}

# 生成综合报告
generate_comprehensive_report() {
    local report_file="$REPORT_DIR/comprehensive_report_$(date +%Y%m%d_%H%M%S).html"
    
    cat > "$report_file" << 'EOF'
<!DOCTYPE html>
<html>
<head>
    <title>日志分析报告</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .header { background-color: #f0f0f0; padding: 10px; }
        .section { margin: 20px 0; }
        .metric { background-color: #e8f4f8; padding: 10px; margin: 5px 0; }
        .error { color: red; }
        .warning { color: orange; }
        .success { color: green; }
        table { border-collapse: collapse; width: 100%; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #f2f2f2; }
    </style>
</head>
<body>
    <div class="header">
        <h1>日志分析报告</h1>
        <p>生成时间: $(date)</p>
    </div>
    
    <div class="section">
        <h2>系统概览</h2>
        <div class="metric">
            <strong>总日志文件数:</strong> $(find /var/log -name "*.log" | wc -l)
        </div>
        <div class="metric">
            <strong>总日志大小:</strong> $(du -sh /var/log | cut -f1)
        </div>
    </div>
    
    <div class="section">
        <h2>错误统计</h2>
        <table>
            <tr><th>日志文件</th><th>ERROR</th><th>WARN</th><th>CRITICAL</th></tr>
EOF

    # 添加错误统计表格
    find /var/log -name "*.log" | while read log_file; do
        local filename=$(basename "$log_file")
        local errors=$(grep -c "ERROR" "$log_file" 2>/dev/null || echo 0)
        local warns=$(grep -c "WARN" "$log_file" 2>/dev/null || echo 0)
        local criticals=$(grep -c "CRITICAL" "$log_file" 2>/dev/null || echo 0)
        
        echo "            <tr><td>$filename</td><td>$errors</td><td>$warns</td><td>$criticals</td></tr>" >> "$report_file"
    done

    cat >> "$report_file" << 'EOF'
        </table>
    </div>
    
    <div class="section">
        <h2>访问统计</h2>
        <p>详细分析请参考各日志文件的单独报告。</p>
    </div>
</body>
</html>
EOF

    log "INFO" "综合报告已生成: $report_file"
}

# 清理旧报告
cleanup_old_reports() {
    log "INFO" "清理旧报告文件..."
    
    find "$REPORT_DIR" -name "*.txt" -mtime +$RETENTION_DAYS -delete
    find "$REPORT_DIR" -name "*.html" -mtime +$RETENTION_DAYS -delete
    
    log "INFO" "旧报告清理完成"
}

# 主分析流程
main() {
    local action="${1:-all}"
    
    case "$action" in
        web)
            analyze_web_logs "/var/log/nginx" "web"
            ;;
        system)
            analyze_system_logs
            ;;
        all)
            analyze_web_logs "/var/log/nginx" "web"
            analyze_system_logs
            generate_comprehensive_report
            cleanup_old_reports
            ;;
        *)
            echo "使用方法: $0 {web|system|all}"
            exit 1
            ;;
    esac
}

# 运行主程序
main "$@"
```

## 4 数据备份脚本

### 4.1 数据库备份脚本

```bash
#!/bin/bash
# 数据库备份脚本
# 功能：自动备份MySQL数据库

# 配置
BACKUP_DIR="/var/backups/mysql"
DB_HOST="localhost"
DB_PORT="3306"
DB_USER="backup"
DB_PASS="backup_password"
RETENTION_DAYS=30
COMPRESSION=true

# 颜色定义
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[0;33m'
NC='\033[0m'

# 日志函数
log() {
    local level="$1"
    shift
    local message="$*"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    mkdir -p "$BACKUP_DIR"
    echo "[$timestamp] [$level] $message" | tee -a "$BACKUP_DIR/backup.log"
}

# 检查依赖
check_dependencies() {
    local required_commands=("mysqldump" "mysql" "gzip" "find")
    
    for cmd in "${required_commands[@]}"; do
        if ! command -v "$cmd" >/dev/null 2>&1; then
            log "ERROR" "缺少必需命令: $cmd"
            exit 1
        fi
    done
    
    log "INFO" "依赖检查通过"
}

# 获取数据库列表
get_databases() {
    mysql -h "$DB_HOST" -P "$DB_PORT" -u "$DB_USER" -p"$DB_PASS" -e "SHOW DATABASES;" 2>/dev/null | \
        grep -v "Database" | \
        grep -v "information_schema" | \
        grep -v "performance_schema" | \
        grep -v "mysql" | \
        grep -v "sys"
}

# 备份单个数据库
backup_database() {
    local db_name="$1"
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local backup_file="$BACKUP_DIR/${db_name}_${timestamp}.sql"
    
    log "INFO" "开始备份数据库: $db_name"
    
    if mysqldump -h "$DB_HOST" -P "$DB_PORT" -u "$DB_USER" -p"$DB_PASS" \
        --single-transaction --routines --triggers --events \
        "$db_name" > "$backup_file" 2>/dev/null; then
        
        if [ "$COMPRESSION" = true ]; then
            gzip "$backup_file"
            backup_file="${backup_file}.gz"
        fi
        
        local file_size=$(du -h "$backup_file" | cut -f1)
        log "INFO" "数据库备份完成: $db_name (${file_size})"
        
        echo "$backup_file"
    else
        log "ERROR" "数据库备份失败: $db_name"
        return 1
    fi
}

# 验证备份
verify_backup() {
    local backup_file="$1"
    local db_name="$2"
    
    log "INFO" "验证备份文件: $(basename "$backup_file")"
    
    if [[ "$backup_file" == *.gz ]]; then
        if ! gzip -t "$backup_file" 2>/dev/null; then
            log "ERROR" "备份文件损坏: $(basename "$backup_file")"
            return 1
        fi
    else
        if ! head -n 10 "$backup_file" | grep -q "mysqldump"; then
            log "ERROR" "备份文件格式不正确: $(basename "$backup_file")"
            return 1
        fi
    fi
    
    log "INFO" "备份验证通过: $(basename "$backup_file")"
    return 0
}

# 清理旧备份
cleanup_old_backups() {
    log "INFO" "清理旧备份文件..."
    
    local deleted_count=0
    
    while IFS= read -r -d '' file; do
        rm -f "$file"
        deleted_count=$((deleted_count + 1))
    done < <(find "$BACKUP_DIR" -name "*.sql*" -type f -mtime +$RETENTION_DAYS -print0)
    
    log "INFO" "清理完成，删除文件数: $deleted_count"
}

# 生成备份报告
generate_backup_report() {
    local report_file="$BACKUP_DIR/backup_report_$(date +%Y%m%d_%H%M%S).txt"
    
    {
        echo "=== MySQL备份报告 ==="
        echo "生成时间: $(date)"
        echo "主机: $DB_HOST"
        echo ""
        
        echo "=== 备份文件列表 ==="
        ls -lh "$BACKUP_DIR"/*.sql* 2>/dev/null || echo "无备份文件"
        echo ""
        
        echo "=== 存储统计 ==="
        echo "总备份大小: $(du -sh "$BACKUP_DIR" | cut -f1)"
        echo "文件数量: $(find "$BACKUP_DIR" -name "*.sql*" -type f | wc -l)"
        echo ""
        
        echo "=== 数据库列表 ==="
        get_databases
    } > "$report_file"
    
    log "INFO" "备份报告已生成: $report_file"
}

# 主备份流程
main() {
    local action="${1:-backup}"
    
    case "$action" in
        backup)
            check_dependencies
            
            local databases=$(get_databases)
            local backup_files=()
            
            for db in $databases; do
                local backup_file=$(backup_database "$db")
                if [ -n "$backup_file" ]; then
                    backup_files+=("$backup_file")
                fi
            done
            
            # 验证备份
            for backup_file in "${backup_files[@]}"; do
                local db_name=$(basename "$backup_file" | cut -d_ -f1)
                verify_backup "$backup_file" "$db_name"
            done
            
            cleanup_old_backups
            generate_backup_report
            ;;
        list)
            echo "数据库列表:"
            get_databases
            ;;
        report)
            generate_backup_report
            ;;
        cleanup)
            cleanup_old_backups
            ;;
        *)
            echo "使用方法: $0 {backup|list|report|cleanup}"
            exit 1
            ;;
    esac
}

# 运行主程序
main "$@"
```

这些实战案例涵盖了系统监控、自动化部署、日志分析和数据备份等常见的Shell脚本应用场景。每个脚本都包含完整的错误处理、日志记录和配置管理功能，可以直接在生产环境中使用。