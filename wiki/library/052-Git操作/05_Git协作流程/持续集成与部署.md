# 持续集成与部署

## CI/CD概述

持续集成与部署（CI/CD）是现代软件开发的核心实践，通过自动化流程提高开发效率和代码质量。

### CI/CD的定义

- **持续集成（CI）**：频繁地将代码集成到主干，通过自动化测试验证代码质量
- **持续交付（CD）**：在CI的基础上，自动将代码部署到测试环境
- **持续部署（CD）**：在持续交付的基础上，自动将代码部署到生产环境

### CI/CD的价值

- **快速反馈**：开发人员快速获得代码质量反馈
- **减少风险**：小批量变更降低发布风险
- **提高质量**：自动化测试确保代码质量
- **加速交付**：自动化流程加速软件交付
- **团队协作**：促进团队协作和知识共享

### CI/CD流程

```mermaid
graph LR
    A[代码提交] --> B[构建]
    B --> C[测试]
    C --> D[代码审查]
    D --> E[部署到测试环境]
    E --> F[验收测试]
    F --> G[部署到生产环境]
    G --> H[监控和反馈]
    H --> A
```

## 持续集成（CI）

### CI基础概念

#### 1. 核心原则

```bash
# 频繁提交
# 开发者每天多次提交代码
# 每次提交都触发构建和测试

# 自动化构建
# 自动编译代码
# 自动安装依赖
# 自动生成构建产物

# 自动化测试
# 单元测试
# 集成测试
# 端到端测试

# 快速反馈
# 构建和测试快速完成
# 及时通知开发者结果
```

#### 2. CI流程

```yaml
# 典型CI流程
steps:
  1. 代码检出
  2. 环境准备
  3. 依赖安装
  4. 代码构建
  5. 单元测试
  6. 代码分析
  7. 集成测试
  8. 构建产物
  9. 结果通知
```

#### 3. CI工具选择

```bash
# GitHub Actions
# 优点：与GitHub深度集成，免费额度大
# 适用：GitHub托管的项目

# GitLab CI
# 优点：与GitLab深度集成，功能全面
# 适用：GitLab托管的项目

# Jenkins
# 优点：插件丰富，高度可定制
# 适用：复杂的企业级项目

# CircleCI
# 优点：配置简单，性能优秀
# 适用：中小型项目
```

### GitHub Actions配置

#### 1. 基础配置

```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        node-version: [14, 16, 18]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run lint
        run: npm run lint
      
      - name: Run tests
        run: npm test
      
      - name: Build project
        run: npm run build
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/lcov.info
```

#### 2. 高级配置

```yaml
# .github/workflows/advanced-ci.yml
name: Advanced CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 2 * * *'  # 每天凌晨2点运行

env:
  NODE_VERSION: '16'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run database migrations
        run: npm run migrate
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test
      
      - name: Run tests
        run: npm run test:ci
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/lcov.info
      
      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results
          path: test-results/
```

#### 3. 并行执行

```yaml
# .github/workflows/parallel-ci.yml
name: Parallel CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '16'
          cache: 'npm'
      - run: npm ci
      - run: npm run lint
  
  test:
    runs-on: ubuntu-latest
    needs: lint
    strategy:
      matrix:
        test-type: [unit, integration, e2e]
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '16'
          cache: 'npm'
      - run: npm ci
      - run: npm run test:${{ matrix.test-type }}
  
  build:
    runs-on: ubuntu-latest
    needs: [lint, test]
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '16'
          cache: 'npm'
      - run: npm ci
      - run: npm run build
      - uses: actions/upload-artifact@v3
        with:
          name: build-files
          path: dist/
```

### GitLab CI配置

#### 1. 基础配置

```yaml
# .gitlab-ci.yml
stages:
  - test
  - build
  - deploy

variables:
  NODE_VERSION: "16"
  DOCKER_DRIVER: overlay2

before_script:
  - apt-get update -qq
  - apt-get install -y -qq nodejs npm
  - npm ci

cache:
  paths:
    - node_modules/

lint:
  stage: test
  script:
    - npm run lint
  only:
    - main
    - develop
    - merge_requests

test:
  stage: test
  script:
    - npm test
    - npm run test:coverage
  coverage: '/Lines\s*:\s*(\d+\.?\d*)%/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage/cobertura-coverage.xml
  only:
    - main
    - develop
    - merge_requests

build:
  stage: build
  script:
    - npm run build
  artifacts:
    paths:
      - dist/
  only:
    - main
    - develop
```

#### 2. Docker集成

```yaml
# .gitlab-ci.yml
stages:
  - test
  - build
  - deploy

variables:
  DOCKER_REGISTRY: "$CI_REGISTRY"
  DOCKER_BACKEND_IMAGE: "$CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA"
  DOCKER_FRONTEND_IMAGE: "$CI_REGISTRY_IMAGE/frontend:$CI_COMMIT_SHA"

services:
  - docker:20.10.16-dind

before_script:
  - docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" "$CI_REGISTRY"

test:
  stage: test
  image: node:16
  script:
    - npm ci
    - npm test
  only:
    - main
    - develop
    - merge_requests

build-backend:
  stage: build
  script:
    - docker build -t "$DOCKER_BACKEND_IMAGE" -f Dockerfile.backend .
    - docker push "$DOCKER_BACKEND_IMAGE"
  only:
    - main
    - develop

build-frontend:
  stage: build
  script:
    - docker build -t "$DOCKER_FRONTEND_IMAGE" -f Dockerfile.frontend .
    - docker push "$DOCKER_FRONTEND_IMAGE"
  only:
    - main
    - develop
```

#### 3. 环境部署

```yaml
# .gitlab-ci.yml
stages:
  - test
  - build
  - deploy-staging
  - deploy-production

deploy-staging:
  stage: deploy-staging
  script:
    - echo "Deploying to staging environment"
    - ssh user@staging-server "docker pull $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA"
    - ssh user@staging-server "docker pull $CI_REGISTRY_IMAGE/frontend:$CI_COMMIT_SHA"
    - ssh user@staging-server "docker-compose -f docker-compose.staging.yml up -d"
  environment:
    name: staging
    url: https://staging.example.com
  only:
    - develop
  when: manual

deploy-production:
  stage: deploy-production
  script:
    - echo "Deploying to production environment"
    - ssh user@production-server "docker pull $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA"
    - ssh user@production-server "docker pull $CI_REGISTRY_IMAGE/frontend:$CI_COMMIT_SHA"
    - ssh user@production-server "docker-compose -f docker-compose.production.yml up -d"
  environment:
    name: production
    url: https://example.com
  only:
    - main
  when: manual
```

## 持续部署（CD）

### CD基础概念

#### 1. 部署策略

```bash
# 蓝绿部署
# 蓝环境：当前生产环境
# 绿环境：新版本环境
# 切换流量：从蓝到绿
# 回滚：快速切换回蓝环境

# 滚动部署
# 逐步替换实例
# 每次替换一部分
# 监控健康状况
# 继续或停止部署

# 金丝雀部署
# 部署到少量实例
# 监控关键指标
# 逐步扩大范围
# 全量部署或回滚
```

#### 2. 环境管理

```bash
# 开发环境
# 用于日常开发
# 自动部署
# 快速迭代

# 测试环境
# 用于功能测试
# 自动部署
# 完整测试套件

# 预发布环境
# 模拟生产环境
# 手动部署
# 最终验证

# 生产环境
# 真实用户环境
# 手动部署
# 严格监控
```

#### 3. 部署自动化

```bash
# 自动化部署流程
# 1. 代码构建
# 2. 容器化
# 3. 推送到仓库
# 4. 部署到环境
# 5. 健康检查
# 6. 通知结果

# 部署工具
# Kubernetes：容器编排
# Docker Compose：多容器管理
# Ansible：配置管理
# Terraform：基础设施即代码
```

### Kubernetes部署

#### 1. 基础配置

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
  labels:
    app: myapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: myapp:latest
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          value: "production"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: myapp-secrets
              key: database-url
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
```

#### 2. 服务配置

```yaml
# k8s/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  selector:
    app: myapp
  ports:
    - protocol: TCP
      port: 80
      targetPort: 3000
  type: LoadBalancer
```

#### 3. Ingress配置

```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - example.com
    secretName: example-com-tls
  rules:
  - host: example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: myapp-service
            port:
              number: 80
```

### Docker部署

#### 1. Dockerfile配置

```dockerfile
# Dockerfile
FROM node:16-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY . .
RUN npm run build

EXPOSE 3000

CMD ["npm", "start"]
```

#### 2. Docker Compose配置

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://user:password@db:5432/myapp
    depends_on:
      - db
      - redis
    networks:
      - app-network

  db:
    image: postgres:13
    environment:
      - POSTGRES_DB=myapp
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    volumes:
      - db-data:/var/lib/postgresql/data
    networks:
      - app-network

  redis:
    image: redis:6-alpine
    networks:
      - app-network

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - app
    networks:
      - app-network

volumes:
  db-data:

networks:
  app-network:
    driver: bridge
```

#### 3. 多环境配置

```yaml
# docker-compose.staging.yml
version: '3.8'

services:
  app:
    build: .
    environment:
      - NODE_ENV=staging
      - DATABASE_URL=postgresql://user:password@staging-db:5432/myapp
    depends_on:
      - staging-db

  staging-db:
    image: postgres:13
    environment:
      - POSTGRES_DB=myapp
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    volumes:
      - staging-db-data:/var/lib/postgresql/data

volumes:
  staging-db-data:

# docker-compose.production.yml
version: '3.8'

services:
  app:
    build: .
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://user:password@production-db:5432/myapp
    depends_on:
      - production-db

  production-db:
    image: postgres:13
    environment:
      - POSTGRES_DB=myapp
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    volumes:
      - production-db-data:/var/lib/postgresql/data

volumes:
  production-db-data:
```

### 传统服务器部署

#### 1. SSH部署脚本

```bash
#!/bin/bash
# deploy.sh

set -e

# 配置
SERVER="user@server.com"
APP_DIR="/var/www/myapp"
BACKUP_DIR="/var/backups/myapp"
REPO_URL="https://github.com/user/myapp.git"

# 创建备份
ssh $SERVER "mkdir -p $BACKUP_DIR"
ssh $SERVER "cp -r $APP_DIR $BACKUP_DIR/myapp-$(date +%Y%m%d-%H%M%S)"

# 部署新版本
ssh $SERVER "cd $APP_DIR && git pull origin main"
ssh $SERVER "cd $APP_DIR && npm ci --production"
ssh $SERVER "cd $APP_DIR && npm run build"

# 重启服务
ssh $SERVER "pm2 restart myapp"

# 健康检查
sleep 10
if curl -f http://example.com/health > /dev/null 2>&1; then
    echo "部署成功"
else
    echo "部署失败，正在回滚"
    ssh $SERVER "cp -r $BACKUP_DIR/myapp-$(date +%Y%m%d-%H%M%S)/* $APP_DIR"
    ssh $SERVER "pm2 restart myapp"
    exit 1
fi
```

#### 2. PM2配置

```javascript
// ecosystem.config.js
module.exports = {
  apps: [{
    name: 'myapp',
    script: 'app.js',
    instances: 'max',
    exec_mode: 'cluster',
    env: {
      NODE_ENV: 'development',
      PORT: 3000
    },
    env_staging: {
      NODE_ENV: 'staging',
      PORT: 3000
    },
    env_production: {
      NODE_ENV: 'production',
      PORT: 3000
    }
  }]
};
```

#### 3. Nginx配置

```nginx
# /etc/nginx/sites-available/myapp
server {
    listen 80;
    server_name example.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name example.com;
    
    ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;
    
    location / {
        proxy_pass http://localhost:3000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }
    
    location /health {
        access_log off;
        return 200 "healthy\n";
    }
}
```

## 监控与反馈

### 监控系统

#### 1. 应用监控

```javascript
// 监控中间件
const prometheus = require('prom-client');
const express = require('express');
const app = express();

// 创建指标
const httpRequestDurationMicroseconds = new prometheus.Histogram({
  name: 'http_request_duration_ms',
  help: 'Duration of HTTP requests in ms',
  labelNames: ['method', 'route', 'code'],
  buckets: [50, 100, 200, 300, 400, 500, 1000]
});

const totalRequests = new prometheus.Counter({
  name: 'total_requests',
  help: 'Total number of requests',
  labelNames: ['method', 'route']
});

// 监控中间件
app.use((req, res, next) => {
  const end = httpRequestDurationMicroseconds.startTimer();
  
  res.on('finish', () => {
    totalRequests.inc({ method: req.method, route: req.route.path });
    end({ route: req.route.path, code: res.statusCode, method: req.method });
  });
  
  next();
});

// 监控端点
app.get('/metrics', (req, res) => {
  res.set('Content-Type', prometheus.register.contentType);
  res.end(prometheus.register.metrics());
});
```

#### 2. 日志监控

```javascript
// 日志配置
const winston = require('winston');
const { combine, timestamp, printf } = winston.format;

const logFormat = printf(({ level, message, timestamp }) => {
  return `${timestamp} [${level}]: ${message}`;
});

const logger = winston.createLogger({
  level: 'info',
  format: combine(
    timestamp(),
    logFormat
  ),
  transports: [
    new winston.transports.Console(),
    new winston.transports.File({ filename: 'combined.log' }),
    new winston.transports.File({ filename: 'error.log', level: 'error' })
  ]
});

// 错误处理
app.use((err, req, res, next) => {
  logger.error(err.stack);
  res.status(500).send('Something broke!');
});
```

#### 3. 性能监控

```javascript
// 性能监控
const NodeCache = require('node-cache');
const cache = new NodeCache({ stdTTL: 600 });

// 响应时间监控
app.use((req, res, next) => {
  const start = Date.now();
  
  res.on('finish', () => {
    const duration = Date.now() - start;
    const key = `response_time:${req.route.path}`;
    
    // 记录响应时间
    const times = cache.get(key) || [];
    times.push(duration);
    cache.set(key, times);
    
    // 如果响应时间过长，记录警告
    if (duration > 1000) {
      logger.warn(`Slow response: ${req.method} ${req.route.path} - ${duration}ms`);
    }
  });
  
  next();
});
```

### 告警系统

#### 1. 告警规则

```yaml
# prometheus-alerts.yml
groups:
- name: myapp-alerts
  rules:
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 10m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value }} errors per second"
  
  - alert: HighResponseTime
    expr: histogram_quantile(0.95, http_request_duration_ms_bucket) > 1000
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High response time detected"
      description: "95th percentile response time is {{ $value }}ms"
  
  - alert: LowMemory
    expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) < 0.1
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Low memory available"
      description: "Only {{ $value }}% memory available"
```

#### 2. 通知配置

```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@example.com'
  smtp_auth_username: 'alerts@example.com'
  smtp_auth_password: 'password'

templates:
  - '/etc/alertmanager/templates/*.tmpl'

route:
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

receivers:
- name: 'web.hook'
  email_configs:
  - to: 'team@example.com'
    subject: 'Alert: {{ .GroupLabels.alertname }}'
    body: |
      {{ range .Alerts }}
      Alert: {{ .Annotations.summary }}
      Description: {{ .Annotations.description }}
      {{ end }}
  webhook_configs:
  - url: 'http://127.0.0.1:5001/'
  slack_configs:
  - api_url: 'https://hooks.slack.com/services/...'
    channel: '#alerts'
    title: 'Alert: {{ .GroupLabels.alertname }}'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ end }}'
```

#### 3. 自动恢复

```bash
#!/bin/bash
# auto-recovery.sh

# 检查应用健康状态
if ! curl -f http://example.com/health > /dev/null 2>&1; then
    echo "应用不健康，尝试重启"
    
    # 重启应用
    ssh user@server "pm2 restart myapp"
    
    # 等待重启完成
    sleep 30
    
    # 再次检查
    if ! curl -f http://example.com/health > /dev/null 2>&1; then
        echo "重启失败，发送告警"
        # 发送告警通知
        curl -X POST -H 'Content-type: application/json' \
            --data '{"text":"应用重启失败，需要人工干预"}' \
            https://hooks.slack.com/services/...
    else
        echo "重启成功"
    fi
fi
```

### 反馈循环

#### 1. 部署反馈

```yaml
# .github/workflows/deploy-feedback.yml
name: Deploy Feedback

on:
  status:

jobs:
  notify:
    if: github.context.status == 'failure'
    runs-on: ubuntu-latest
    steps:
      - name: Notify deployment failure
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          fields: repo,message,commit,author,action,eventName,ref,workflow
          text: '部署失败，请检查'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

#### 2. 性能反馈

```javascript
// 性能分析中间件
const performanceAnalysis = (req, res, next) => {
  const start = process.hrtime();
  
  res.on('finish', () => {
    const [seconds, nanoseconds] = process.hrtime(start);
    const duration = seconds * 1000 + nanoseconds / 1000000;
    
    // 记录性能数据
    if (duration > 1000) {
      logger.warn(`Slow request: ${req.method} ${req.url} - ${duration}ms`);
      
      // 发送到监控系统
      metrics.record('slow_request', {
        method: req.method,
        url: req.url,
        duration: duration
      });
    }
  });
  
  next();
};
```

#### 3. 用户反馈

```javascript
// 用户反馈收集
app.post('/api/feedback', async (req, res) => {
  const { type, message, rating } = req.body;
  
  try {
    // 保存反馈
    await Feedback.create({
      type,
      message,
      rating,
      timestamp: new Date(),
      userAgent: req.headers['user-agent'],
      ip: req.ip
    });
    
    // 如果是负面反馈，发送告警
    if (rating <= 2) {\      await sendAlert({
        title: 'Negative user feedback',
        message: `User reported: ${message}`,
        severity: 'warning'
      });
    }
    
    res.json({ success: true });
  } catch (error) {
    logger.error('Failed to save feedback:', error);
    res.status(500).json({ error: 'Failed to save feedback' });
  }
});
```

## 最佳实践与优化

### CI/CD最佳实践

#### 1. 管道优化

```yaml
# 优化CI/CD管道
# 1. 并行执行任务
# 2. 使用缓存
# 3. 优化构建顺序
# 4. 减少不必要的步骤

# 示例：优化的GitHub Actions
name: Optimized CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:\        test-type: [lint, unit, integration]
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '16'
          cache: 'npm'
      - run: npm ci
      - run: npm run test:${{ matrix.test-type }}
```

#### 2. 安全实践

```bash
# 安全最佳实践
# 1. 使用密钥管理
# 2. 扫描安全漏洞
# 3. 限制权限
# 4. 审计日志

# 示例：安全扫描
- name: Run security scan
  run: |
    npm audit --audit-level moderate
    npm run security-scan

# 示例：密钥管理
env:
  DATABASE_URL: ${{ secrets.DATABASE_URL }}
  API_KEY: ${{ secrets.API_KEY }}
```

#### 3. 成本优化

```bash
# 成本优化策略
# 1. 使用自托管Runner
# 2. 优化构建时间
# 3. 清理资源
# 4. 监控成本

# 示例：成本监控
- name: Monitor build costs
  run: |
    echo "Build duration: ${{ job.status }}"
    echo "Resources used: ${{ runner.name }}"
```

### 性能优化

#### 1. 构建优化

```bash
# 构建优化策略
# 1. 使用缓存
# 2. 并行构建
# 3. 增量构建
# 4. 优化依赖

# 示例：Docker构建优化
FROM node:16-alpine as builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM node:16-alpine as runner
WORKDIR /app
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/dist ./dist
COPY package*.json ./
EXPOSE 3000
CMD ["npm", "start"]
```

#### 2. 部署优化

```bash
# 部署优化策略
# 1. 滚动部署
# 2. 蓝绿部署
# 3. 金丝雀部署
# 4. 零停机部署

# 示例：Kubernetes滚动更新
strategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 1
    maxSurge: 1
```

#### 3. 监控优化

```bash
# 监控优化策略
# 1. 采样率优化
# 2. 告警阈值优化
# 3. 数据聚合
# 4. 存储优化

# 示例：采样率配置
metrics:
  sampling_rate: 0.1  # 10%采样率
  aggregation_interval: 60s
```

### 故障处理

#### 1. 故障检测

```bash
# 故障检测策略
# 1. 健康检查
# 2. 指标监控
# 3. 日志分析
# 4. 用户反馈

# 示例：健康检查
app.get('/health', (req, res) => {
  const checks = {
    database: checkDatabase(),
    redis: checkRedis(),
    external: checkExternalServices()
  };
  
  const isHealthy = Object.values(checks).every(check => check.healthy);
  
  res.status(isHealthy ? 200 : 503).json(checks);
});
```

#### 2. 故障恢复

```bash
# 故障恢复策略
# 1. 自动重启
# 2. 自动回滚
# 3. 流量切换
# 4. 人工干预

# 示例：自动回滚
- name: Auto rollback on failure
  if: failure()
  run: |
    echo "Deployment failed, rolling back"
    kubectl rollout undo deployment/myapp
```

#### 3. 故障分析

```bash
# 故障分析策略
# 1. 日志收集
# 2. 指标分析
# 3. 根因分析
# 4. 改进措施

# 示例：故障分析脚本
#!/bin/bash
# analyze-failure.sh

echo "=== 故障分析报告 ==="
echo "时间: $(date)"
echo "部署: $DEPLOYMENT_ID"
echo "环境: $ENVIRONMENT"

echo "\n=== 错误日志 ==="
kubectl logs deployment/myapp --tail=100

echo "\n=== 性能指标 ==="
curl -s http://monitoring:9090/api/v1/query?query=up

echo "\n=== 建议措施 ==="
echo "1. 检查数据库连接"
echo "2. 验证配置文件"
echo "3. 监控资源使用情况"
```

## 总结

持续集成与部署是现代软件开发的最佳实践，通过自动化流程提高开发效率、代码质量和部署可靠性。

### 关键要点

1. **自动化是核心**：尽可能自动化所有流程
2. **快速反馈**：建立快速反馈机制
3. **质量保证**：通过自动化测试保证质量
4. **监控告警**：建立完善的监控和告警系统
5. **持续改进**：不断优化CI/CD流程

### 实施建议

- **从小开始**：先实施基础的CI流程
- **逐步扩展**：逐步添加CD和监控功能
- **团队培训**：培训团队成员掌握CI/CD技能
- **工具选择**：选择适合团队的CI/CD工具
- **持续优化**：根据实际情况持续优化流程

通过有效的CI/CD实践，团队可以实现快速、可靠、高质量的软件交付，提高用户满意度，降低运营成本，实现业务的可持续发展。