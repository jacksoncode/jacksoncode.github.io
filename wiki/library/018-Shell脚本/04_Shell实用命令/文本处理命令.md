# 文本处理命令

## 文本处理概述

在Shell环境中，文本处理是一项核心任务。无论是日志分析、数据处理还是系统管理，都需要强大的文本处理能力。Linux/Unix系统提供了丰富的文本处理命令，这些命令可以单独使用，也可以通过管道组合使用，形成强大的文本处理流水线。

## 基础文本查看命令

### cat命令

cat命令用于连接文件并打印到标准输出。

```bash
#!/bin/bash

# 创建示例文件
echo -e "第一行\n第二行\n第三行" > sample.txt
echo -e "第四行\n第五行\n第六行" > sample2.txt

# 基本用法
echo "=== cat命令示例 ==="
echo "显示文件内容:"
cat sample.txt

echo -e "\n连接多个文件:"
cat sample.txt sample2.txt

echo -e "\n显示行号:"
cat -n sample.txt

echo -e "\n压缩空行:"
echo -e "行1\n\n\n行2" > spaced.txt
cat -s spaced.txt
rm spaced.txt

echo -e "\n从标准输入读取:"
echo "输入几行文本，按Ctrl+D结束:"
# cat > input.txt  # 交互式示例

# 实用技巧
echo -e "\n创建文件:"
echo "这是新文件的内容" > newfile.txt
cat newfile.txt

echo -e "\n追加内容:"
echo "追加的内容" >> newfile.txt
cat newfile.txt
```

### less和more命令

less和more命令用于分页查看文件内容。

```bash
#!/bin/bash

# 创建大文件用于演示
seq 1 100 > large_file.txt

echo "=== less和more命令示例 ==="
echo "less命令功能更强大，支持向前和向后翻页"
echo "常用快捷键:"
echo "  空格键 - 向下翻页"
echo "  b - 向上翻页"
echo "  /pattern - 向下搜索"
echo "  ?pattern - 向上搜索"
echo "  q - 退出"
echo "  g - 跳到文件开头"
echo "  G - 跳到文件结尾"
echo "  数字+G - 跳到指定行"

# less large_file.txt  # 交互式命令

echo -e "\nmore命令只能向前翻页"
echo "常用快捷键:"
echo "  空格键 - 向下翻页"
echo "  回车键 - 向下一行"
echo "  q - 退出"

# more large_file.txt  # 交互式命令

# 清理
rm large_file.txt
```

### head和tail命令

head和tail命令分别用于查看文件的开头和结尾部分。

```bash
#!/bin/bash

# 创建示例文件
seq 1 20 > numbers.txt

echo "=== head和tail命令示例 ==="

echo "head命令 - 查看文件开头:"
echo "默认显示前10行:"
head numbers.txt

echo -e "\n显示前5行:"
head -n 5 numbers.txt

echo -e "\n显示前5个字节:"
head -c 5 numbers.txt

echo -e "\ntail命令 - 查看文件结尾:"
echo "默认显示后10行:"
tail numbers.txt

echo -e "\n显示后5行:"
tail -n 5 numbers.txt

echo -e "\n显示后5个字节:"
tail -c 5 numbers.txt

echo -e "\n实时监控文件变化 (Ctrl+C退出):"
echo "tail -f numbers.txt"
# 演示时可以手动执行: tail -f numbers.txt

# 清理
rm numbers.txt
```

## 文本搜索和匹配命令

### grep命令

grep是最常用的文本搜索命令，用于在文件中搜索指定模式。

```bash
#!/bin/bash

# 创建示例文件
cat > employees.txt << EOF
张三,工程师,北京,25,15000
李四,设计师,上海,28,12000
王五,工程师,北京,30,18000
赵六,销售,广州,26,10000
钱七,工程师,深圳,32,20000
孙八,设计师,北京,27,13000
EOF

echo "=== grep命令示例 ==="

echo "基本搜索 - 查找包含'工程师'的行:"
grep "工程师" employees.txt

echo -e "\n显示行号:"
grep -n "工程师" employees.txt

echo -e "\n忽略大小写:"
echo "Beijing" > cities.txt
grep -i "beijing" cities.txt

echo -e "\n反向匹配 (显示不匹配的行):"
grep -v "北京" employees.txt

echo -e "\n只显示匹配的部分:"
grep -o "工程师" employees.txt

echo -e "\n统计匹配行数:"
grep -c "工程师" employees.txt

echo -e "\n递归搜索目录:"
mkdir -p test_dir
echo "测试文件" > test_dir/test.txt
# grep -r "测试" test_dir/

echo -e "\n使用正则表达式:"
grep "^[张王钱]" employees.txt  # 姓氏以张、王、钱开头的行

echo -e "\n显示匹配行的前后几行:"
grep -A 1 -B 1 "设计师" employees.txt  # 显示匹配行及前后各1行

# 清理
rm employees.txt cities.txt
rm -rf test_dir
```

### egrep和fgrep命令

egrep支持扩展正则表达式，fgrep进行固定字符串匹配。

```bash
#!/bin/bash

# 创建示例文件
cat > data.txt << EOF
abc123
def456
ghi789
abc.def
test@email.com
phone: 138-1234-5678
EOF

echo "=== egrep和fgrep命令示例 ==="

echo "egrep - 扩展正则表达式:"
echo "支持 | (或) 操作符:"
egrep "abc|def" data.txt

echo -e "\n支持 + (一个或多个) 和 ? (零个或一个):"
egrep "abc+" data.txt  # 匹配abc, abcc, abccc等

echo -e "\nfgrep - 固定字符串匹配 (不解释正则表达式):"
echo "匹配包含点号的行:"
fgrep "." data.txt  # 会匹配包含实际点号的行

echo -e "\n对比grep处理点号:"
grep "." data.txt   # 点号作为正则表达式匹配任意字符

# 清理
rm data.txt
```

## 文本处理和转换命令

### sed命令

sed是流编辑器，用于对文本进行编辑和转换。

```bash
#!/bin/bash

# 创建示例文件
cat > inventory.txt << EOF
苹果 100 5.50
香蕉 200 3.20
橙子 150 4.00
苹果 50 5.50
葡萄 80 8.00
EOF

echo "=== sed命令示例 ==="

echo "替换文本 - 将'苹果'替换为'红富士苹果':"
sed "s/苹果/红富士苹果/" inventory.txt

echo -e "\n全局替换 (替换每行所有匹配项):"
echo "aaa bbb aaa" > test.txt
sed "s/aaa/xxx/g" test.txt

echo -e "\n指定行替换:"
sed "2s/苹果/红富士苹果/" inventory.txt  # 只替换第2行

echo -e "\n多行替换:"
sed "1,3s/苹果/红富士苹果/" inventory.txt  # 替换第1到3行

echo -e "\n删除行:"
echo "删除包含'橙子'的行:"
sed "/橙子/d" inventory.txt

echo -e "\n插入行:"
echo "在包含'香蕉'的行前插入新行:"
sed "/香蕉/i\\
新到货品
" inventory.txt

echo -e "\n追加行:"
echo "在包含'葡萄'的行后追加新行:"
sed "/葡萄/a\\
热销商品
" inventory.txt

echo -e "\n使用正则表达式:"
echo "将价格格式化为两位小数:"
sed "s/\([0-9]*\)\.\([0-9]\)\>/\1.\20/g" inventory.txt

echo -e "\n保存修改到文件:"
# sed -i "s/苹果/红富士苹果/g" inventory.txt

# 清理
rm inventory.txt test.txt
```

### awk命令

awk是一种强大的文本分析和处理工具。

```bash
#!/bin/bash

# 创建示例文件
cat > sales.txt << EOF
2023-01-01 张三 电脑 5000
2023-01-02 李四 手机 3000
2023-01-03 王五 电脑 5000
2023-01-04 赵六 平板 2000
2023-01-05 钱七 手机 3000
EOF

echo "=== awk命令示例 ==="

echo "基本用法 - 打印指定列:"
echo "打印销售人员 (第2列):"
awk '{print $2}' sales.txt

echo -e "\n打印多个字段:"
awk '{print $2, $4}' sales.txt  # 打印第2列和第4列

echo -e "\n字段分隔符:"
echo "使用自定义分隔符:"
echo "name:age:city" > info.txt
awk -F: '{print $1, $3}' info.txt

echo -e "\n条件处理:"
echo "只打印销售额大于3000的记录:"
awk '$4 > 3000 {print $0}' sales.txt

echo -e "\n计算总和:"
awk '{sum += $4} END {print "总销售额:", sum}' sales.txt

echo -e "\n统计记录数:"
awk 'END {print "总记录数:", NR}' sales.txt

echo -e "\n格式化输出:"
awk '{printf "日期: %-10s 销售: %-5s 金额: %s\n", $1, $2, $4}' sales.txt

echo -e "\n使用BEGIN和END:"
awk 'BEGIN {print "=== 销售报告 ==="} {print $2, $4} END {print "=== 报告结束 ==="}' sales.txt

echo -e "\n字符串操作:"
awk '{print toupper($2)}' sales.txt  # 转换为大写

# 清理
rm sales.txt info.txt
```

## 文本排序和去重命令

### sort命令

sort命令用于对文本行进行排序。

```bash
#!/bin/bash

# 创建示例文件
cat > students.txt << EOF
张三 85
李四 92
王五 78
赵六 92
钱七 88
孙八 78
EOF

echo "=== sort命令示例 ==="

echo "默认排序 (按字母顺序):"
sort students.txt

echo -e "\n按数值排序:"
sort -n students.txt  # 按第2列数值排序

echo -e "\n按指定列排序:"
sort -k2 -n students.txt  # 按第2列数值排序

echo -e "\n逆序排序:"
sort -r students.txt

echo -e "\n去除重复行:"
echo -e "apple\nbanana\napple\ncherry\nbanana" > fruits.txt
sort -u fruits.txt

echo -e "\n合并已排序的文件:"
echo -e "apple\ncherry" > file1.txt
echo -e "banana\ndate" > file2.txt
sort -m file1.txt file2.txt

# 清理
rm students.txt fruits.txt file1.txt file2.txt
```

### uniq命令

uniq命令用于去除或查找重复的行。

```bash
#!/bin/bash

# 创建示例文件
cat > log.txt << EOF
ERROR: 连接失败
INFO: 用户登录
INFO: 用户登录
WARNING: 磁盘空间不足
ERROR: 连接失败
INFO: 数据处理完成
WARNING: 磁盘空间不足
EOF

echo "=== uniq命令示例 ==="

echo "注意: uniq只处理相邻的重复行，通常与sort结合使用"

echo -e "\n去除相邻重复行:"
uniq log.txt

echo -e "\n先排序再去重:"
sort log.txt | uniq

echo -e "\n显示重复行的次数:"
sort log.txt | uniq -c

echo -e "\n只显示重复的行:"
sort log.txt | uniq -d

echo -e "\n只显示不重复的行:"
sort log.txt | uniq -u

echo -e "\n忽略前N个字段:"
echo -e "1 apple\n2 apple\n3 banana" > data.txt
uniq -f 1 data.txt  # 忽略第1个字段

# 清理
rm log.txt data.txt
```

## 文本统计命令

### wc命令

wc命令用于统计文件的行数、字数和字节数。

```bash
#!/bin/bash

# 创建示例文件
cat > article.txt << EOF
这是第一段文本。
这是第二段文本，包含更多的内容。
第三段文本。
EOF

echo "=== wc命令示例 ==="

echo "统计行数、字数、字节数:"
wc article.txt

echo -e "\n只统计行数:"
wc -l article.txt

echo -e "\n只统计字数:"
wc -w article.txt

echo -e "\n只统计字节数:"
wc -c article.txt

echo -e "\n统计字符数 (包括换行符):"
wc -m article.txt

echo -e "\n最长行的字符数:"
wc -L article.txt

echo -e "\n统计多个文件:"
echo "Hello World" > file1.txt
echo "Shell Scripting" > file2.txt
wc -l file1.txt file2.txt

# 清理
rm article.txt file1.txt file2.txt
```

## 实际应用示例

### 日志分析脚本

```bash
#!/bin/bash

# 创建示例日志文件
cat > access.log << EOF
192.168.1.100 - - [01/Jan/2023:10:00:01 +0000] "GET /index.html HTTP/1.1" 200 1234
192.168.1.101 - - [01/Jan/2023:10:00:02 +0000] "POST /login HTTP/1.1" 404 0
192.168.1.102 - - [01/Jan/2023:10:00:03 +0000] "GET /style.css HTTP/1.1" 200 567
192.168.1.100 - - [01/Jan/2023:10:00:04 +0000] "GET /script.js HTTP/1.1" 500 0
192.168.1.103 - - [01/Jan/2023:10:00:05 +0000] "GET /index.html HTTP/1.1" 200 1234
192.168.1.101 - - [01/Jan/2023:10:00:06 +0000] "GET /favicon.ico HTTP/1.1" 404 0
EOF

# 日志分析函数
analyze_logs() {
    local log_file=$1
    
    echo "=== Web访问日志分析报告 ==="
    
    # 总请求数
    local total_requests=$(wc -l < "$log_file")
    echo "总请求数: $total_requests"
    
    # 状态码统计
    echo -e "\n状态码统计:"
    awk '{print $9}' "$log_file" | sort | uniq -c | sort -nr
    
    # 最常见的页面
    echo -e "\n最常见的页面:"
    awk '{print $7}' "$log_file" | sort | uniq -c | sort -nr | head -5
    
    # IP访问统计
    echo -e "\nIP访问统计 (前5名):"
    awk '{print $1}' "$log_file" | sort | uniq -c | sort -nr | head -5
    
    # 错误请求统计
    echo -e "\n4xx和5xx错误统计:"
    awk '$9 >= 400 {print $9}' "$log_file" | sort | uniq -c | sort -nr
    
    # 流量统计
    echo -e "\n总流量 (字节):"
    awk '{sum += $10} END {print sum}' "$log_file"
}

# 运行分析
analyze_logs "access.log"

# 清理
rm access.log
```

### 数据处理脚本

```bash
#!/bin/bash

# 创建示例销售数据
cat > sales_data.csv << EOF
日期,销售员,产品,数量,单价
2023-01-01,张三,电脑,2,5000
2023-01-02,李四,手机,5,3000
2023-01-03,王五,平板,3,2000
2023-01-04,张三,手机,2,3000
2023-01-05,李四,电脑,1,5000
2023-01-06,王五,配件,10,100
EOF

# 销售数据分析函数
analyze_sales() {
    local csv_file=$1
    
    echo "=== 销售数据分析报告 ==="
    
    # 跳过标题行处理数据
    local data_lines=$(tail -n +2 "$csv_file")
    
    # 总销售额
    echo "总销售额:"
    echo "$data_lines" | awk -F, 'BEGIN {total=0} {total += $4*$5} END {print total}'
    
    # 各销售员业绩
    echo -e "\n销售员业绩:"
    echo "$data_lines" | awk -F, '{sales[$2] += $4*$5} END {for (name in sales) print name, sales[name]}' | sort -k2 -nr
    
    # 各产品销售情况
    echo -e "\n产品销售情况:"
    echo "$data_lines" | awk -F, '{products[$3] += $4} END {for (product in products) print product, products[product]}' | sort -k2 -nr
    
    # 最佳销售日
    echo -e "\n最佳销售日:"
    echo "$data_lines" | awk -F, '{daily[$1] += $4*$5} END {for (date in daily) print date, daily[date]}' | sort -k2 -nr | head -1
}

# 运行分析
analyze_sales "sales_data.csv"

# 清理
rm sales_data.csv
```

## 最佳实践

1. **组合使用命令**：通过管道将多个命令组合使用，形成强大的处理流水线
2. **使用适当的选项**：熟悉各命令的常用选项，提高处理效率
3. **处理大文件**：对于大文件，考虑使用流式处理而不是一次性加载
4. **备份重要文件**：在修改文件前，先进行备份
5. **测试正则表达式**：复杂正则表达式应先进行测试验证
6. **注意字符编码**：处理文本时注意字符编码问题
7. **使用临时文件**：复杂处理过程可以使用临时文件暂存中间结果

## 总结

文本处理命令是Shell环境中最强大的功能之一。通过本章的学习，你应该掌握了：

1. 基础文本查看命令（cat、less、more、head、tail）
2. 文本搜索命令（grep系列）
3. 文本处理和转换命令（sed、awk）
4. 文本排序和去重命令（sort、uniq）
5. 文本统计命令（wc）
6. 实际应用场景和最佳实践

熟练掌握这些文本处理命令，将大大提高你在Shell环境中的工作效率。在下一章中，我们将学习进程管理命令，进一步增强系统管理能力。